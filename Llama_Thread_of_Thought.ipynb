{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7tlS5spaWRc"
      },
      "source": [
        "Code to deploy Llama3: https://www.analyticsvidhya.com/blog/2024/04/how-to-run-llama-3-locally/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hy0vG_pmOY_4"
      },
      "source": [
        "## Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7NBDgf_pIfZS"
      },
      "outputs": [],
      "source": [
        "!pip install -U \"transformers==4.40.0\" --upgrade\n",
        "!pip install -i https://pypi.org/simple/ bitsandbytes\n",
        "!pip install accelerate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kx8LzAiDOhy7"
      },
      "source": [
        "## Download Llama 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w6rEsdO_IxPV"
      },
      "outputs": [],
      "source": [
        "import transformers\n",
        "import torch\n",
        "\n",
        "model_id = \"unsloth/llama-3-8b-Instruct-bnb-4bit\"\n",
        "\n",
        "pipeline = transformers.pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model_id,\n",
        "    model_kwargs={\n",
        "        \"torch_dtype\": torch.float16,\n",
        "        \"quantization_config\": {\"load_in_4bit\": True},\n",
        "        \"low_cpu_mem_usage\": True,\n",
        "    },\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KnysTccigPk2"
      },
      "source": [
        "## Query Llama 3"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fallacies = \"\"\"\n",
        "Fallacy of Credibility: Abusive Ad Hominem; Ad Populum; Appeal to False Authority;\n",
        "Appeal to Nature; Appeal to Tradition; Guilt by Association; Tu Quoque.\n",
        "Fallacy of Logic: Causal Oversimplification; Circular Reasoning; Equivocation;\n",
        "False Analogy; False Causality; False Dilemma; Hasty Generalization; Slippery Slope; Straw Man; Fallacy of Division.\n",
        "Appeal to Emotion: Appeal to Positive Emotion; Appeal to Anger; Appeal to Fear;\n",
        "Appeal to Pity; Appeal to Ridicule; Appeal to Worse Problem.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "FyRd3ns8wreR"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fallacies_with_examples = \"\"\"\n",
        "Slippery slope:\\n\\nIf we ban assault rifles, next they'll ban all guns, and before you know it, we'll be living in a police state.,\n",
        "Hasty generalization:\\n\\nI met two people from New York City, and both were rude. Therefore, all New Yorkers are rude.,\n",
        "False analogy:\\n\\nComparing buying a car to choosing a spouse is a false analogy because the two situations are vastly different.,\n",
        "Guilt by association:\\n\\nYou shouldn't listen to John's opinion on politics; he's friends with several criminals.,\n",
        "Causal oversimplification:\\n\\nThe rise in crime rates is due to violent video games; therefore, banning them will solve the problem.,\n",
        "Ad populum:\\n\\nEveryone is buying the new smartphone, so it must be the best one on the market.,\n",
        "Circular reasoning:\\n\\nThe Bible is the word of God because God says it is in the Bible.,\n",
        "Appeal to fear:\\n\\nIf you don't vote for me, your taxes will skyrocket and crime will run rampant.,\n",
        "False causality:\\n\\nEvery time I wash my car, it rains. Therefore, washing my car causes rain.,\n",
        "Fallacy of division:\\n\\nThat company is profitable, so all of its employees must be well-paid.,\n",
        "Appeal to ridicule:\\n\\nYou shouldn't listen to Mary's argument about climate change; she believes the Earth is flat!,\n",
        "Appeal to worse problems:\\n\\nWhy are we worrying about pollution when there are children starving in the world?,\n",
        "Abusive ad hominem:\\n\\nYou can't trust anything Tom says; he's just a loser.,\n",
        "Appeal to false authority:\\n\\nMy doctor says that smoking is good for you, so it must be true.,\n",
        "Appeal to positive emotion:\\n\\nIf you care about the environment, you'll buy this eco-friendly product.,\n",
        "Appeal to nature:\\n\\nNatural remedies are always better than pharmaceutical drugs.,\n",
        "Equivocation:\\n\\nThe sign said 'Fine for parking here,' so I thought it would be fine to park there.,\n",
        "Appeal to anger:\\n\\nYou wouldn't want to be a coward, would you? Then you better join the military!,\n",
        "False dilemma:\\n\\nEither we ban all guns or we'll continue to have mass shootings.,\n",
        "Straw man:\\n\\nOpponents of gun control argue that we should give guns to everyone, including criminals and children.,\n",
        "Appeal to tradition:\\n\\nWe should continue to use fossil fuels because that's how we've always done it.,\n",
        "Tu quoque:\\n\\nYou say I shouldn't smoke, but I've seen you smoke before!\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "IrTIE9PU4TM4"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Version â„–1: Vanilla zero-shot version of ToT prompting."
      ],
      "metadata": {
        "id": "1EhdDNhdvGFO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "CWeoOFzAbf2h"
      },
      "outputs": [],
      "source": [
        "def tot_prompt_1(input_text):\n",
        "    messages = [\n",
        "        {\"role\"   : \"system\",\n",
        "        \"content\": \"You are a helpful assistant!\"},\n",
        "        {\"role\"   : \"user\",\n",
        "        \"content\":\n",
        "        f\"As a content reviewer, I provide multiple fallacies which might occur in the text; \\\n",
        "        you need to identify the falacies if there're such in the text.\\\n",
        "        {fallacies}\\\n",
        "        Text: {input_text}\\\n",
        "        Walk me through this context in manageable parts step by step, \\\n",
        "        summarizing and analyzing as we go.\\\n",
        "        Answer:\\\n",
        "        \"},\n",
        "    ]\n",
        "\n",
        "    prompt = pipeline.tokenizer.apply_chat_template(\n",
        "            messages,\n",
        "            tokenize=False,\n",
        "            add_generation_prompt=True\n",
        "    )\n",
        "\n",
        "    terminators = [\n",
        "        pipeline.tokenizer.eos_token_id,\n",
        "        pipeline.tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
        "    ]\n",
        "\n",
        "    outputs = pipeline(\n",
        "        prompt,\n",
        "        max_new_tokens=512,\n",
        "        eos_token_id=terminators,\n",
        "        do_sample=True,\n",
        "        temperature=0.6,\n",
        "        top_p=0.9,\n",
        "    )\n",
        "    return outputs[0][\"generated_text\"][len(prompt):]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The answer is \"false analogy\", model is CORRECT\n",
        "print(tot_prompt_1(input_text=\n",
        "             \"\"\"\n",
        "             TITLE: There is a difference between a'smurf' and an'alt'.\n",
        "             Please learn it and stop using them interchangeably. POST: Someone once told me\n",
        "             they have an'alt' cause their main account was too high of rank to play with their\n",
        "             friends. It's exactly the same as smurfing.\n",
        "             \"\"\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kbMq2xyGvBW4",
        "outputId": "cd86394a-fbd8-48e5-8621-42ff20b73b6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I'd be happy to help you identify potential fallacies in the text.\n",
            "\n",
            "**Step 1: Summary**\n",
            "The text is about the difference between \"smurf\" and \"alt\". The author is responding to someone who mentioned having an \"alt\" because their main account was too high-rank to play with friends, and the author claims it's the same as \"smurfing\".\n",
            "\n",
            "**Step 2: Analysis**\n",
            "Let's break down the text into smaller parts:\n",
            "\n",
            "* \"Someone once told me they have an'alt' cause their main account was too high of rank to play with their friends.\"\n",
            "\t+ This statement appears to be an anecdote, but it could be an Appeal to Authority fallacy if the person who told the author is not a credible source.\n",
            "* \"It's exactly the same as smurfing.\"\n",
            "\t+ This statement seems to be an opinion or a comparison, but it could be a False Analogy fallacy if the author is not providing a valid comparison between \"smurfing\" and having an \"alt\".\n",
            "* The author's tone is instructive, which could be an Appeal to Emotion (Appeal to Ridicule) if they're using a condescending tone to shame the person for not understanding the difference.\n",
            "\n",
            "**Fallacies identified:**\n",
            "\n",
            "* Appeal to Authority (or possibly Appeal to False Authority if the person who told the author is not a credible source)\n",
            "* False Analogy\n",
            "* Appeal to Emotion (Appeal to Ridicule)\n",
            "\n",
            "Please let me know if you'd like me to elaborate on these fallacies or if you'd like to review the text further!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The answer is \"circular reasoning\", model is NOT CORRECT\n",
        "print(tot_prompt_1(input_text=\n",
        "             \"\"\"\n",
        "             America is the best place to live, because it's better than any other country.\n",
        "             \"\"\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HPpRTuJtwMJk",
        "outputId": "14ef7469-1918-4feb-c7f8-c47ed1e20423"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Let's break down the text and identify any potential fallacies.\n",
            "\n",
            "**Initial Statement:** \"America is the best place to live, because it's better than any other country.\"\n",
            "\n",
            "**Step 1: Identify the Claim**\n",
            "\n",
            "The claim is that America is the best place to live. The speaker is making a statement about the superiority of America compared to other countries.\n",
            "\n",
            "**Step 2: Identify the Reason**\n",
            "\n",
            "The reason given for this claim is that \"it's better than any other country.\" This is a very general and vague statement, which raises some red flags.\n",
            "\n",
            "**Step 3: Analyze the Reason**\n",
            "\n",
            "The reason given is an example of a **Fallacy of Credibility: Appeal to False Authority**. The speaker is implying that America is the best place to live simply because it's better than other countries, without providing any evidence or specific reasons to support this claim. This is a weak and unconvincing argument, as it relies on an unsubstantiated claim rather than providing actual evidence.\n",
            "\n",
            "**Step 4: Identify any other potential fallacies**\n",
            "\n",
            "Upon closer inspection, we can also identify a **Fallacy of Logic: False Dilemma**. The speaker presents a binary choice, implying that America is either the best place to live or the worst. This oversimplifies the complexity of the issue and ignores the possibility that other countries might have their own unique advantages and disadvantages.\n",
            "\n",
            "**Step 5: Evaluate the overall argument**\n",
            "\n",
            "The argument presented is weak and lacks substance. It relies on an unsubstantiated claim and oversimplifies the issue. To make a convincing argument, the speaker would need to provide evidence and specific reasons to support the claim that America is the best place to live.\n",
            "\n",
            "Overall, the text contains a Fallacy of Credibility (Appeal to False Authority) and a Fallacy of Logic (False Dilemma).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The answer is \"causal oversimplification\" and \"false causality\", model is NOT CORRECT\n",
        "print(tot_prompt_1(input_text=\n",
        "             \"\"\"\n",
        "             The last Democrat winner of the New Hampshire primary won the general election.\n",
        "             This year, the winner of the New Hampshire primary will win the general election.\n",
        "             \"\"\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZTNZwTTWwUAr",
        "outputId": "9d3721ce-5182-4cf0-da60-cb7476da2a5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I'd be happy to help you identify any fallacies in the given text. Let's break it down step by step.\n",
            "\n",
            "**Step 1: Identify the text**\n",
            "The text consists of two sentences:\n",
            "\n",
            "1. \"The last Democrat winner of the New Hampshire primary won the general election.\"\n",
            "2. \"This year, the winner of the New Hampshire primary will win the general election.\"\n",
            "\n",
            "**Step 2: Analyze the text**\n",
            "\n",
            "The text appears to be making a claim about the relationship between winning the New Hampshire primary and winning the general election. The claim is based on the experience of the last Democrat winner of the New Hampshire primary, who allegedly won the general election.\n",
            "\n",
            "**Step 3: Identify the fallacy**\n",
            "\n",
            "The fallacy present in this text is the:\n",
            "\n",
            "* **Appeal to Unrepresentative Sample** (also known as the Fallacy of Credibility: Guilt by Association)\n",
            "\n",
            "The text assumes that the experience of the last Democrat winner of the New Hampshire primary is representative of all future winners. However, this is an unjustified assumption, as there may be many factors that differ between the last winner and future winners, making it an unrepresentative sample.\n",
            "\n",
            "The text is essentially saying, \"Since the last Democrat winner of the New Hampshire primary won the general election, all future winners will also win.\" This is a non-sequitur, as the experience of the last winner does not guarantee the outcome for future winners.\n",
            "\n",
            "By identifying this fallacy, we can recognize that the text is making an unjustified claim and that further evidence is needed to support the claim that the winner of the New Hampshire primary will always win the general election.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Version â„–2: Vanilla zero-shot version of ToT prompting with modified output."
      ],
      "metadata": {
        "id": "6LJ2NZdxvMp1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "F0dIzb8heaZ5"
      },
      "outputs": [],
      "source": [
        "def tot_prompt_2(input_text):\n",
        "    messages = [\n",
        "            {\"role\"   : \"system\",\n",
        "            \"content\": \"You are a helpful assistant!\"},\n",
        "            {\"role\"   : \"user\",\n",
        "            \"content\":\n",
        "            f\"As a content reviewer, I provide multiple fallacies which might occur in the text; \\\n",
        "            you need to identify the falacies if there're such in the text, else return 'no fallacy'.\\\n",
        "            {fallacies}\\\n",
        "            Text: {input_text}\\\n",
        "            Walk me through this context in manageable parts step by step, \\\n",
        "            summarizing and analyzing as we go. \\\n",
        "            Then, output just the identified fallacies on the last line separated by ';'.\\\n",
        "            Answer:\\\n",
        "            \"},\n",
        "    ]\n",
        "\n",
        "    prompt = pipeline.tokenizer.apply_chat_template(\n",
        "            messages,\n",
        "            tokenize=False,\n",
        "            add_generation_prompt=True\n",
        "    )\n",
        "\n",
        "    terminators = [\n",
        "        pipeline.tokenizer.eos_token_id,\n",
        "        pipeline.tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
        "    ]\n",
        "\n",
        "    outputs = pipeline(\n",
        "        prompt,\n",
        "        max_new_tokens=512,\n",
        "        eos_token_id=terminators,\n",
        "        do_sample=True,\n",
        "        temperature=0.6,\n",
        "        top_p=0.9,\n",
        "    )\n",
        "\n",
        "    return outputs[0][\"generated_text\"][len(prompt):]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "sQwH_Uo4uDW_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff9380dc-1187-44ea-8819-7b413da2fe69"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Let's break down the text into manageable parts and analyze it step by step.\n",
            "\n",
            "**Part 1:** TITLE: There is a difference between a'smurf' and an 'alt'.\n",
            "\n",
            "* The title sets the tone for the discussion, claiming that there is a difference between two terms. However, it doesn't provide any context or explanation about what these terms mean or why they are different.\n",
            "\n",
            "**Part 2:** POST: Someone once told me they have an 'alt' cause their main account was too high of rank to play with their friends. It's exactly the same as smurfing.\n",
            "\n",
            "* The poster shares a personal anecdote about someone having an 'alt' account because their main account was too high in rank to play with friends. They then claim that this is the same as smurfing.\n",
            "\n",
            "**Analysis:**\n",
            "\n",
            "* The poster is trying to establish a connection between having an 'alt' account and smurfing, but the connection is not clearly explained. It seems like the poster is making an assumption or drawing a conclusion without providing sufficient evidence.\n",
            "* The use of the phrase \"it's exactly the same\" implies that the poster believes there is a direct equivalence between having an 'alt' account and smurfing, but this equivalence is not demonstrated.\n",
            "\n",
            "**Identified fallacies:**\n",
            "\n",
            "Appeal to False Authority (the poster is presenting a personal anecdote as evidence, but it's not a reliable source); False Analogy (the poster is drawing an analogy between having an 'alt' account and smurfing without providing sufficient evidence); Appeal to Emotion (the poster is trying to persuade by using a sense of familiarity and similarity, rather than presenting a logical argument).\n",
            "\n",
            "Fallacies: Appeal to False Authority; False Analogy; Appeal to Emotion\n"
          ]
        }
      ],
      "source": [
        "# The answer is \"false analogy\", model is CORRECT\n",
        "print(tot_prompt_2(input_text=\n",
        "             \"\"\"\n",
        "             TITLE: There is a difference between a'smurf' and an'alt'.\n",
        "             Please learn it and stop using them interchangeably. POST: Someone once told me\n",
        "             they have an'alt' cause their main account was too high of rank to play with their\n",
        "             friends. It's exactly the same as smurfing.\n",
        "             \"\"\"))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The answer is \"circular reasoning\", model is NOT CORRECT\n",
        "print(tot_prompt_2(input_text=\n",
        "             \"\"\"\n",
        "             America is the best place to live, because it's better than any other country.\n",
        "             \"\"\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9m3_T0Ch3APR",
        "outputId": "cabccd68-afd2-4790-93a4-9e1a2c1a62da"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Let's break down the text step by step and analyze it.\n",
            "\n",
            "**Step 1: Identify the claim**\n",
            "The claim is \"America is the best place to live, because it's better than any other country.\"\n",
            "\n",
            "**Step 2: Identify the reasoning**\n",
            "The reasoning is simply \"because it's better than any other country.\" This is a very weak and vague justification.\n",
            "\n",
            "**Step 3: Analyze the reasoning**\n",
            "The reasoning is an example of a **Fallacy of Credibility: Appeal to False Authority**. The speaker is implying that America is the best place to live simply because it's better than other countries, without providing any evidence or credible sources to support this claim. This is a false authority because it's not a reliable or credible source.\n",
            "\n",
            "**Step 4: Identify any emotional appeals**\n",
            "There is no apparent emotional appeal in this text.\n",
            "\n",
            "**Step 5: Identify any logical fallacies**\n",
            "There is a **Fallacy of Logic: False Causality**. The speaker is implying that being better than other countries is the cause of America being the best place to live, but this is not a logical or causal relationship.\n",
            "\n",
            "**Step 6: Summarize and analyze**\n",
            "The text is a weak and unsubstantiated claim that relies on a false authority and a false causality. It does not provide any evidence or credible sources to support the claim, and it does not engage with counterarguments or alternative perspectives.\n",
            "\n",
            "**Identified fallacies:**\n",
            "Appeal to False Authority; False Causality\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The answer is \"causal oversimplification\" and \"false causality\", model is NOT CORRECT\n",
        "print(tot_prompt_2(input_text=\n",
        "             \"\"\"\n",
        "             The last Democrat winner of the New Hampshire primary won the general election.\n",
        "             This year, the winner of the New Hampshire primary will win the general election.\n",
        "             \"\"\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sqmsd36M3AnQ",
        "outputId": "0058b7d2-4d1f-4458-93e4-4854f12fb3a1"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Let's break down the text step by step:\n",
            "\n",
            "1. The first sentence states: \"The last Democrat winner of the New Hampshire primary won the general election.\"\n",
            "\n",
            "This sentence is making a factual claim about the past. It's stating that the winner of the New Hampshire primary in the past (specifically, the last Democrat winner) went on to win the general election.\n",
            "\n",
            "2. The second sentence states: \"This year, the winner of the New Hampshire primary will win the general election.\"\n",
            "\n",
            "This sentence is making a prediction about the future. It's stating that the winner of the New Hampshire primary this year will also go on to win the general election.\n",
            "\n",
            "The connection between the two sentences is that the speaker is trying to draw a conclusion about the future based on the past. Specifically, they're saying that because the last Democrat winner of the New Hampshire primary won the general election, this year's winner will do the same.\n",
            "\n",
            "However, this conclusion relies on an assumption that may not be valid. Just because something happened in the past doesn't necessarily mean it will happen again in the future. There may be many factors that could affect the outcome of this year's election, such as changes in voter demographics, candidate platforms, or external events.\n",
            "\n",
            "The fallacies present in this text are:\n",
            "\n",
            "Appeal to False Authority (the speaker is relying on an unproven assumption about the past to make a prediction about the future); and\n",
            "\n",
            "Hasty Generalization (the speaker is generalizing from a single data point to make a sweeping conclusion about the future).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The answer is \"slippery slope\", model is NOT CORRECT\n",
        "print(tot_prompt_2(input_text=\n",
        "             \"\"\"\n",
        "             TITLE: Gatineau police officer tests positive, but masks still not mandatory at checkpoints POST:\n",
        "             Guess what? police need to interact with people at close quarters. they often need to touch or grapple.\n",
        "             The masks do little. Cool it. Once they wear masks your anxiety will force you to demand the next step.\n",
        "             biohazard suits? get real.\n",
        "             \"\"\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9l5Gy_lx-VPn",
        "outputId": "88d7706d-8b18-45e5-9035-7af159382a52"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Let's break down the text step by step:\n",
            "\n",
            "**Step 1:** The title mentions a Gatineau police officer testing positive for COVID-19, but masks are not mandatory at checkpoints.\n",
            "\n",
            "**Step 2:** The author starts by stating that police officers need to interact with people at close quarters, which implies that they are at risk of contracting COVID-19.\n",
            "\n",
            "**Step 3:** The author claims that masks do little to prevent the spread of COVID-19, and that people will become anxious and demand more drastic measures (such as biohazard suits) if masks are worn.\n",
            "\n",
            "**Step 4:** The author seems to be dismissing the idea of wearing masks, implying that it's an overreaction.\n",
            "\n",
            "Now, let's analyze the text:\n",
            "\n",
            "* The author is using a personal anecdote (\"Guess what?\") to grab the reader's attention, which could be seen as an attempt to establish credibility (Fallacy of Credibility: Appeal to Personal Experience).\n",
            "* The author is downplaying the effectiveness of masks, which could be seen as an Appeal to Fear (Fallacy of Emotion: Appeal to Fear).\n",
            "* The author is implying that people will become overly anxious if masks are worn, which could be seen as an Appeal to Ridicule (Fallacy of Emotion: Appeal to Ridicule).\n",
            "* The author is dismissing the idea of wearing masks without providing any evidence or alternative solutions, which could be seen as a Fallacy of Logic: False Dilemma.\n",
            "\n",
            "The identified fallacies are:\n",
            "\n",
            "Appeal to Personal Experience; Appeal to Fear; Appeal to Ridicule; False Dilemma\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The answer is \"appeal to nature\", model is CORRECT\n",
        "print(tot_prompt_2(input_text=\n",
        "             \"\"\"\n",
        "             TITLE: Sweden sees higher coronavirus death rate than US after refusing lockdown POST:\n",
        "             I wonder how is New York planning on getting out of the lockdown,\n",
        "             because when they get out of lockdown probably some cases are going to be going\n",
        "             on and the whole infection thing will start again. POST: You cant stop nature.\n",
        "             Youre going to be infected if you havent already. We are always trying to fight nature.\n",
        "             We just have to let it run its course.\n",
        "             \"\"\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bPU8y70p-2Gw",
        "outputId": "439e82f2-9bc8-4702-e4d9-16df16faf8c8"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Let's break down the context step by step.\n",
            "\n",
            "**Part 1:**\n",
            "The original post wonders how New York will get out of the lockdown, suggesting that when the lockdown is lifted, the infection will start again.\n",
            "\n",
            "**Part 2:**\n",
            "The second post responds, saying that you can't stop nature and that people will get infected if they haven't already. The post also mentions that humans are always trying to fight nature and that we just need to let it run its course.\n",
            "\n",
            "**Analysis:**\n",
            "\n",
            "* The second post is using an Appeal to Nature fallacy, suggesting that nature is unstoppable and that humans should just accept it.\n",
            "* The post is also using a False Analogy fallacy, comparing the natural world to a force that can't be controlled, when in reality, humans have successfully controlled and mitigated the spread of diseases through public health measures.\n",
            "* Additionally, the post is using a Tu Quoque fallacy, implying that the first post is trying to fight nature, which is not a relevant or accurate criticism.\n",
            "\n",
            "**Identified Fallacies:**\n",
            "Appeal to Nature; False Analogy; Tu Quoque\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The answer is \"no fallacy\", model is NOT CORRECT\n",
        "print(tot_prompt_2(input_text=\n",
        "             \"\"\"\n",
        "             The sea-ice loss is President Vladimir Putin' s gain.\n",
        "             Already the largest country on the planet, Russia stands to gain\n",
        "             access to shipping routes and energy reserves, and a strategic\n",
        "             military advantage from the opening of the Arctic. Along the Russian\n",
        "             coastline, which makes up more than half the Arctic total, winds\n",
        "             and currents push old ice away from potential shipping lanes and\n",
        "             prevent the build-up of thicker, multi-year ice that would leave\n",
        "             other parts of the Arctic impassable for longer periods.\n",
        "             \"\"\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MHb4i_uV_ajw",
        "outputId": "8c3bf48e-e134-4b1f-c90a-19c4504b0c21"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Let's break down the text into manageable parts and analyze it step by step.\n",
            "\n",
            "**Part 1:** \"The sea-ice loss is President Vladimir Putin's gain.\"\n",
            "\n",
            "* This statement seems to be making a connection between the sea-ice loss and President Putin's gain. However, it's not clear what specific benefit Putin would gain from the sea-ice loss.\n",
            "\n",
            "**Part 2:** \"Already the largest country on the planet, Russia stands to gain access to shipping routes and energy reserves, and a strategic military advantage from the opening of the Arctic.\"\n",
            "\n",
            "* This statement is making a claim about the benefits Russia would gain from the opening of the Arctic. However, it's not clear what specific evidence or reasoning is being used to support this claim.\n",
            "\n",
            "**Part 3:** \"Along the Russian coastline, which makes up more than half the Arctic total, winds and currents push old ice away from potential shipping lanes and prevent the build-up of thicker, multi-year ice that would leave other parts of the Arctic impassable for longer periods.\"\n",
            "\n",
            "* This statement is providing some scientific information about the movement of ice along the Russian coastline. However, it's not clear how this information is being used to support the claim about Russia's gain from the sea-ice loss.\n",
            "\n",
            "**Analysis:**\n",
            "\n",
            "The text appears to be making an argument that Russia would benefit from the sea-ice loss, but it's not clear what specific evidence or reasoning is being used to support this claim. The text relies heavily on vague statements and generalities, rather than providing specific data or evidence to support its claims.\n",
            "\n",
            "**Identified Fallacies:**\n",
            "\n",
            "Ad Hominem (Fallacy of Credibility); Appeal to False Authority (Fallacy of Credibility); False Dilemma (Fallacy of Logic); Appeal to Fear (Appeal to Emotion).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Version â„–3: Vanilla few-shot version of ToT prompting."
      ],
      "metadata": {
        "id": "uVSl10lG3POo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tot_prompt_3(input_text):\n",
        "    messages = [\n",
        "        {\"role\"   : \"system\",\n",
        "            \"content\": \"You are an expert in detecting logical fallacies!\"},\n",
        "            {\"role\"   : \"user\",\n",
        "            \"content\":\n",
        "            f\"As a content reviewer, I provide multiple fallacies and their examples which might occur in the text; \\\n",
        "            you need to identify the falacies if there're such in the text, else return 'no fallacy'.\\\n",
        "            {fallacies_with_examples}\\\n",
        "            Text: {input_text}\\\n",
        "            Walk me through this context in manageable parts step by step, \\\n",
        "            summarizing and analyzing as we go.\\\n",
        "            Then, provide only fallacies separated by ';' or the 'no fallacy' label.\\\n",
        "            Answer:\\\n",
        "            \"},\n",
        "    ]\n",
        "    prompt = pipeline.tokenizer.apply_chat_template(\n",
        "            messages,\n",
        "            tokenize=False,\n",
        "            add_generation_prompt=True\n",
        "    )\n",
        "\n",
        "    terminators = [\n",
        "        pipeline.tokenizer.eos_token_id,\n",
        "        pipeline.tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
        "    ]\n",
        "\n",
        "    outputs = pipeline(\n",
        "        prompt,\n",
        "        max_new_tokens=512,\n",
        "        eos_token_id=terminators,\n",
        "        do_sample=True,\n",
        "        temperature=0.6,\n",
        "        top_p=0.9,\n",
        "    )\n",
        "\n",
        "    return outputs[0][\"generated_text\"][len(prompt):]"
      ],
      "metadata": {
        "id": "NVngsA4I5BLW"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The answer is \"false analogy\", model is CORRECT\n",
        "print(tot_prompt_3(input_text=\n",
        "             \"\"\"\n",
        "             TITLE: There is a difference between a'smurf' and an'alt'.\n",
        "             Please learn it and stop using them interchangeably. POST: Someone once told me\n",
        "             they have an'alt' cause their main account was too high of rank to play with their\n",
        "             friends. It's exactly the same as smurfing.\n",
        "             \"\"\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xgIKptIG61WQ",
        "outputId": "e2abeed7-e271-4db2-9b82-abe406851e87"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Let's break down the text step by step and analyze it.\n",
            "\n",
            "**Step 1:** The text is discussing a difference between a \"smurf\" and an \"alt\".\n",
            "\n",
            "**Step 2:** The author mentions someone telling them that they have an \"alt\" because their main account was too high of rank to play with their friends. The author argues that this is the same as smurfing.\n",
            "\n",
            "**Analysis:** The author is trying to make a point about the difference between a \"smurf\" and an \"alt\", but they are using a flawed analogy to do so. The situation described is not equivalent to smurfing, which is typically used to describe a player switching between multiple characters to gain an unfair advantage. The author's example is more about a player having a secondary account to play with friends, which is not the same thing.\n",
            "\n",
            "**Fallacies identified:** Tu quoque; False analogy\n",
            "\n",
            "The text contains a Tu quoque fallacy because the author is attacking the person who told them about the \"alt\" by saying that their example is not the same as smurfing. The author is trying to discredit the person's argument by pointing out that it's not a perfect analogy, rather than addressing the actual issue.\n",
            "\n",
            "The text also contains a False analogy fallacy because the author is trying to equate the situation described with smurfing, which is not a valid comparison.\n",
            "\n",
            "Output: Tu quoque; False analogy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The answer is \"circular reasoning\", model is NOT CORRECT\n",
        "print(tot_prompt_3(input_text=\n",
        "             \"\"\"\n",
        "             America is the best place to live, because it's better than any other country.\n",
        "             \"\"\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oeJVAyCH7ClY",
        "outputId": "8323cbe0-01d8-42ac-a8c2-21878193676f"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Let's break down the text step by step:\n",
            "\n",
            "1. The statement claims that \"America is the best place to live\" without providing any evidence or justification.\n",
            "\n",
            "Summary: The statement makes a bold claim about America being the best place to live, but it lacks any supporting evidence or reasoning.\n",
            "\n",
            "Analysis: The statement appears to be a subjective opinion or a value judgment, and it's not clear what criteria are being used to determine what makes a place \"the best.\" This lack of specificity and evidence makes it difficult to evaluate the claim.\n",
            "\n",
            "2. The statement compares America to \"any other country,\" implying that there is a direct comparison between America and all other countries.\n",
            "\n",
            "Summary: The statement is making a comparison between America and other countries, but it's not clear what specific aspects of these countries are being compared.\n",
            "\n",
            "Analysis: The statement may be committing a false analogy fallacy, as the comparison between America and other countries is not specified or justified. Additionally, the statement may be committing a hasty generalization fallacy, as it's not clear what evidence or data are being used to support the claim that America is better than other countries.\n",
            "\n",
            "3. The statement does not provide any evidence or justification for why America is the best place to live.\n",
            "\n",
            "Summary: The statement lacks any supporting evidence or reasoning to justify the claim that America is the best place to live.\n",
            "\n",
            "Analysis: The statement may be committing a bald assertion fallacy, as it's making a claim without providing any evidence or justification to support it.\n",
            "\n",
            "Identified fallacies: no fallacy; appeal to ignorance; false analogy; hasty generalization; bald assertion\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The answer is \"causal oversimplification\" and \"false causality\", model is NOT CORRECT\n",
        "print(tot_prompt_3(input_text=\n",
        "             \"\"\"\n",
        "             The last Democrat winner of the New Hampshire primary won the general election.\n",
        "             This year, the winner of the New Hampshire primary will win the general election.\n",
        "             \"\"\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zw93BICD7N7Y",
        "outputId": "9ee8a8ae-6c3f-4ef4-98bd-3b5de4d66870"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Let's break down the text step by step.\n",
            "\n",
            "**Step 1: Identify the claim**\n",
            "The claim is: \"This year, the winner of the New Hampshire primary will win the general election.\"\n",
            "\n",
            "**Step 2: Analyze the claim**\n",
            "The claim is making a prediction about the outcome of the general election based on the outcome of the New Hampshire primary. However, there is no logical connection between the two. The claim is relying on a single data point (the last Democrat winner of the New Hampshire primary winning the general election) to make a prediction about a future event.\n",
            "\n",
            "**Step 3: Identify the fallacy**\n",
            "The fallacy committed here is **Hasty generalization**. The claim is making a generalization about the outcome of the general election based on a single data point, without considering other relevant factors that might affect the outcome.\n",
            "\n",
            "**Step 4: Output the identified fallacy**\n",
            "The identified fallacy is: Hasty generalization.\n",
            "\n",
            "So, the output is:\n",
            "Hasty generalization\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The answer is \"slippery slope\", model is NOT CORRECT\n",
        "print(tot_prompt_3(input_text=\n",
        "             \"\"\"\n",
        "             TITLE: Gatineau police officer tests positive, but masks still not mandatory at checkpoints POST:\n",
        "             Guess what? police need to interact with people at close quarters. they often need to touch or grapple.\n",
        "             The masks do little. Cool it. Once they wear masks your anxiety will force you to demand the next step.\n",
        "             biohazard suits? get real.\n",
        "             \"\"\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EF23hzIE-G3H",
        "outputId": "873df7c8-0517-4b76-8abd-dc0de055c85f"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Let's break down the text step by step.\n",
            "\n",
            "**Part 1:** The author starts by stating that police officers need to interact with people at close quarters, which requires physical contact.\n",
            "\n",
            "**Summary:** The author is setting the context for why police officers might not need to wear masks.\n",
            "\n",
            "**Analysis:** So far, the text is providing a factual context, and there is no fallacy detected.\n",
            "\n",
            "**Part 2:** The author claims that masks do little to prevent the spread of disease.\n",
            "\n",
            "**Summary:** The author is expressing skepticism about the effectiveness of masks.\n",
            "\n",
            "**Analysis:** This statement is an opinion, but it's not a fallacy yet.\n",
            "\n",
            "**Part 3:** The author warns that if people wear masks, they will become anxious and demand more protection, such as biohazard suits.\n",
            "\n",
            "**Summary:** The author is predicting a hypothetical scenario.\n",
            "\n",
            "**Analysis:** This statement is an opinion, and it's where the fallacy might be hiding.\n",
            "\n",
            "**Part 4:** The author concludes by telling the reader to \"cool it\" and not demand more protection.\n",
            "\n",
            "**Summary:** The author is advising the reader to be calm and not demand more protection.\n",
            "\n",
            "**Analysis:** This conclusion is an opinion, and it's where the fallacy is likely to be.\n",
            "\n",
            "**Identified Fallacies:**\n",
            "\n",
            "After analyzing the text, I identify the following fallacies:\n",
            "\n",
            "* Appeal to ridicule: The author is using a sarcastic tone to dismiss the idea of wearing masks, which is an appeal to ridicule.\n",
            "* False analogy: The author is comparing the need for masks to the need for biohazard suits, which is a false analogy.\n",
            "* Appeal to fear: The author is warning that if people wear masks, they will become anxious and demand more protection, which is an appeal to fear.\n",
            "\n",
            "The identified fallacies are: Appeal to ridicule; False analogy; Appeal to fear.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The answer is \"appeal to nature\", model is CORRECT\n",
        "print(tot_prompt_3(input_text=\n",
        "             \"\"\"\n",
        "             TITLE: Sweden sees higher coronavirus death rate than US after refusing lockdown POST:\n",
        "             I wonder how is New York planning on getting out of the lockdown,\n",
        "             because when they get out of lockdown probably some cases are going to be going\n",
        "             on and the whole infection thing will start again. POST: You cant stop nature.\n",
        "             Youre going to be infected if you havent already. We are always trying to fight nature.\n",
        "             We just have to let it run its course.\n",
        "             \"\"\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RPnSn8KZ-hK4",
        "outputId": "dc438732-d987-4d81-92dd-ee97d60d934e"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Let's break down the text step by step:\n",
            "\n",
            "**Post 1**\n",
            "\"I wonder how is New York planning on getting out of the lockdown, because when they get out of lockdown probably some cases are going to be going on and the whole infection thing will start again.\"\n",
            "\n",
            "* This post is making a prediction about the outcome of New York's lockdown. The speaker is wondering how they will exit the lockdown, implying that the current measures are not effective.\n",
            "* This is a hasty generalization, as the speaker is making a broad statement about the effectiveness of lockdowns based on a single example (New York).\n",
            "\n",
            "**Post 2**\n",
            "\"You can't stop nature. You're going to be infected if you haven't already. We are always trying to fight nature. We just have to let it run its course.\"\n",
            "\n",
            "* This post is making a claim that it's impossible to stop the spread of the virus, and that it's natural for people to get infected.\n",
            "* This is an appeal to nature, as the speaker is arguing that the spread of the virus is a natural phenomenon that cannot be stopped.\n",
            "* The speaker is also using a form of fatalism, implying that people are powerless against the virus and should just accept their fate.\n",
            "\n",
            "**Fallacies identified:**\n",
            "hasty generalization; appeal to nature\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The answer is \"no fallacy\", model is CORRECT\n",
        "print(tot_prompt_3(input_text=\n",
        "             \"\"\"\n",
        "             The sea-ice loss is President Vladimir Putin' s gain.\n",
        "             Already the largest country on the planet, Russia stands to gain\n",
        "             access to shipping routes and energy reserves, and a strategic\n",
        "             military advantage from the opening of the Arctic. Along the Russian\n",
        "             coastline, which makes up more than half the Arctic total, winds\n",
        "             and currents push old ice away from potential shipping lanes and\n",
        "             prevent the build-up of thicker, multi-year ice that would leave\n",
        "             other parts of the Arctic impassable for longer periods.\n",
        "             \"\"\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LQUDcsSK_NkE",
        "outputId": "d1608cf5-4001-4cac-e08f-617e911f29f7"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Let's break down the text into manageable parts and analyze it step by step.\n",
            "\n",
            "**Part 1:** \"The sea-ice loss is President Vladimir Putin's gain.\"\n",
            "\n",
            "* Summary: The text claims that the loss of sea ice is beneficial to President Putin.\n",
            "* Analysis: This statement is a vague and unsubstantiated claim. It's unclear what specific benefits Putin would gain from sea ice loss.\n",
            "\n",
            "**Part 2:** \"Already the largest country on the planet, Russia stands to gain access to shipping routes and energy reserves...\"\n",
            "\n",
            "* Summary: The text claims that Russia will gain access to shipping routes and energy reserves due to sea ice loss.\n",
            "* Analysis: This statement is a claim about the benefits of sea ice loss, but it's not clear how this would occur or what the evidence is for this claim.\n",
            "\n",
            "**Part 3:** \"...and a strategic military advantage from the opening of the Arctic.\"\n",
            "\n",
            "* Summary: The text claims that sea ice loss would give Russia a strategic military advantage in the Arctic.\n",
            "* Analysis: This statement is another unsubstantiated claim about the benefits of sea ice loss. It's unclear what specific military advantages Russia would gain or how this would occur.\n",
            "\n",
            "**Part 4:** \"Along the Russian coastline, which makes up more than half the Arctic total, winds and currents push old ice away from potential shipping lanes and prevent the build-up of thicker, multi-year ice...\"\n",
            "\n",
            "* Summary: The text explains that Russia's coastline is affected by winds and currents that push ice away from shipping lanes.\n",
            "* Analysis: This statement is a factual claim about the physical environment of the Arctic. It's not a logical fallacy.\n",
            "\n",
            "**Part 5:** \"...and prevent the build-up of thicker, multi-year ice that would leave other parts of the Arctic impassable for longer periods.\"\n",
            "\n",
            "* Summary: The text explains that the winds and currents prevent the build-up of thick, multi-year ice in other parts of the Arctic.\n",
            "* Analysis: This statement is another factual claim about the physical environment of the Arctic. It's not a logical fallacy.\n",
            "\n",
            "**Conclusion:** After analyzing the text, I did not identify any logical fallacies. The text appears to be making unsubstantiated claims about the benefits of sea ice loss, but it does not contain any obvious logical fallacies.\n",
            "\n",
            "Output:\n",
            "no fallacy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Version â„–4: Advanced zero-shot version of ToT prompting: two-step prompting using reasoning + refining conclusion."
      ],
      "metadata": {
        "id": "-fYLXB6bBNn2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tot_prompt_4(input_text):\n",
        "    # Step 1: Initial reasoning\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant!\"},\n",
        "        {\"role\": \"user\", \"content\":\n",
        "            f\"As a content reviewer, I provide multiple fallacies which might occur in the text; \\\n",
        "            you need to identify the fallacies if there're such in the text, else return 'no fallacy'.\\\n",
        "            {fallacies}\\\n",
        "            Text: {input_text}\\\n",
        "            Walk me through this context in manageable parts step by step, \\\n",
        "            summarizing and analyzing as we go. \\\n",
        "            Answer:\\\n",
        "            \"}\n",
        "    ]\n",
        "\n",
        "    # Generate the initial analysis using the pipeline\n",
        "    prompt = pipeline.tokenizer.apply_chat_template(\n",
        "            messages,\n",
        "            tokenize=False,\n",
        "            add_generation_prompt=True\n",
        "    )\n",
        "\n",
        "    terminators = [\n",
        "        pipeline.tokenizer.eos_token_id,\n",
        "        pipeline.tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
        "    ]\n",
        "\n",
        "    outputs = pipeline(\n",
        "        prompt,\n",
        "        max_new_tokens=512,\n",
        "        eos_token_id=terminators,\n",
        "        do_sample=True,\n",
        "        temperature=0.6,\n",
        "        top_p=0.9,\n",
        "    )\n",
        "\n",
        "    initial_analysis = outputs[0][\"generated_text\"][len(prompt):]\n",
        "\n",
        "    # Step 2: Refining the conclusion\n",
        "    messages_refine = [\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant!\"},\n",
        "        {\"role\": \"user\", \"content\":\n",
        "            f\"Based on the analysis provided, distill the findings into a concise summary. \\\n",
        "            For each identified fallacy, specify the text segment and the corresponding fallacy type. \\\n",
        "            Finally, provide only fallacies separated by ';' or the 'no fallacy' label.\\\n",
        "            Summarize the identified fallacies and their types from the initial analysis:\\\n",
        "            {initial_analysis}\\\n",
        "            Provide only the identified fallacies.\"\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    prompt_refine = pipeline.tokenizer.apply_chat_template(\n",
        "        messages_refine,\n",
        "        tokenize=False,\n",
        "        add_generation_prompt=True\n",
        "    )\n",
        "\n",
        "    outputs_refine = pipeline(\n",
        "        prompt_refine,\n",
        "        max_new_tokens=512,\n",
        "        eos_token_id=terminators,\n",
        "        do_sample=True,\n",
        "        temperature=0.6,\n",
        "        top_p=0.9,\n",
        "    )\n",
        "\n",
        "    refined_output = outputs_refine[0][\"generated_text\"][len(prompt_refine):]\n",
        "\n",
        "    return refined_output"
      ],
      "metadata": {
        "id": "H3RkTNd2BQEk"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The answer is \"false analogy\", model is CORRECT\n",
        "print(tot_prompt_4(input_text=\n",
        "             \"\"\"\n",
        "             TITLE: There is a difference between a'smurf' and an'alt'.\n",
        "             Please learn it and stop using them interchangeably. POST: Someone once told me\n",
        "             they have an'alt' cause their main account was too high of rank to play with their\n",
        "             friends. It's exactly the same as smurfing.\n",
        "             \"\"\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RTuVlCkkF2il",
        "outputId": "fc44a919-4b2c-47b2-9942-0a474daa5c8c"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here is the concise summary:\n",
            "\n",
            "Appeal to False Authority; False Analogy; Causal Oversimplification;\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The answer is \"circular reasoning\", model is NOT CORRECT\n",
        "print(tot_prompt_4(input_text=\n",
        "             \"\"\"\n",
        "             America is the best place to live, because it's better than any other country.\n",
        "             \"\"\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WklMVhh1EBiI",
        "outputId": "c2702424-ea0c-43bb-9bcf-00be774e782e"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Appeal to Ignorance; False Dilemma\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The answer is \"no fallacy\", model is NOT CORRECT\n",
        "print(tot_prompt_4(input_text=\n",
        "             \"\"\"\n",
        "             The sea-ice loss is President Vladimir Putin' s gain.\n",
        "             Already the largest country on the planet, Russia stands to gain\n",
        "             access to shipping routes and energy reserves, and a strategic\n",
        "             military advantage from the opening of the Arctic. Along the Russian\n",
        "             coastline, which makes up more than half the Arctic total, winds\n",
        "             and currents push old ice away from potential shipping lanes and\n",
        "             prevent the build-up of thicker, multi-year ice that would leave\n",
        "             other parts of the Arctic impassable for longer periods.\n",
        "             \"\"\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G8PTpFXxF3jO",
        "outputId": "699c5007-9430-4499-e439-4547bea8b395"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here are the identified fallacies:\n",
            "\n",
            "Appeal to False Authority; Appeal to Fear; False Causality; Hasty Generalization;\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Version â„–5: Advanced few-shot version of ToT prompting: two-step prompting using reasoning + refining conclusion."
      ],
      "metadata": {
        "id": "ruFPe_3DHOBA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tot_prompt_5(input_text):\n",
        "    # Step 1: Initial reasoning\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant!\"},\n",
        "        {\"role\": \"user\", \"content\":\n",
        "            f\"As a content reviewer, I provide multiple fallacies and their examples which might occur in the text; \\\n",
        "            you need to identify the fallacies if there're such in the text, else return 'no fallacy'.\\\n",
        "            {fallacies_with_examples}\\\n",
        "            Text: {input_text}\\\n",
        "            Walk me through this context in manageable parts step by step, \\\n",
        "            summarizing and analyzing as we go. \\\n",
        "            Answer:\\\n",
        "            \"}\n",
        "    ]\n",
        "\n",
        "    # Generate the initial analysis using the pipeline\n",
        "    prompt = pipeline.tokenizer.apply_chat_template(\n",
        "            messages,\n",
        "            tokenize=False,\n",
        "            add_generation_prompt=True\n",
        "    )\n",
        "\n",
        "    terminators = [\n",
        "        pipeline.tokenizer.eos_token_id,\n",
        "        pipeline.tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
        "    ]\n",
        "\n",
        "    outputs = pipeline(\n",
        "        prompt,\n",
        "        max_new_tokens=512,\n",
        "        eos_token_id=terminators,\n",
        "        do_sample=True,\n",
        "        temperature=0.6,\n",
        "        top_p=0.9,\n",
        "    )\n",
        "\n",
        "    initial_analysis = outputs[0][\"generated_text\"][len(prompt):]\n",
        "\n",
        "    # Step 2: Refining the conclusion\n",
        "    messages_refine = [\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant!\"},\n",
        "        {\"role\": \"user\", \"content\":\n",
        "            f\"Based on the analysis provided, distill the findings into a concise summary. \\\n",
        "            For each identified fallacy, specify the text segment and the corresponding fallacy type. \\\n",
        "            Finally, provide only fallacies separated by ';' or the 'no fallacy' label.\\\n",
        "            Summarize the identified fallacies and their types from the initial analysis:\\\n",
        "            {initial_analysis}\\\n",
        "            Provide only the identified fallacies.\"\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    prompt_refine = pipeline.tokenizer.apply_chat_template(\n",
        "        messages_refine,\n",
        "        tokenize=False,\n",
        "        add_generation_prompt=True\n",
        "    )\n",
        "\n",
        "    outputs_refine = pipeline(\n",
        "        prompt_refine,\n",
        "        max_new_tokens=512,\n",
        "        eos_token_id=terminators,\n",
        "        do_sample=True,\n",
        "        temperature=0.6,\n",
        "        top_p=0.9,\n",
        "    )\n",
        "\n",
        "    refined_output = outputs_refine[0][\"generated_text\"][len(prompt_refine):]\n",
        "\n",
        "    return refined_output"
      ],
      "metadata": {
        "id": "tbQDxP0wHSd9"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The answer is \"false analogy\", model is CORRECT\n",
        "print(tot_prompt_5(input_text=\n",
        "             \"\"\"\n",
        "             TITLE: There is a difference between a'smurf' and an'alt'.\n",
        "             Please learn it and stop using them interchangeably. POST: Someone once told me\n",
        "             they have an'alt' cause their main account was too high of rank to play with their\n",
        "             friends. It's exactly the same as smurfing.\n",
        "             \"\"\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wMMD7dfeH-sV",
        "outputId": "9b502f4a-a2d4-4169-b373-ff8f60d8c6ed"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here are the identified fallacies, separated by semicolons:\n",
            "\n",
            "False analogy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The answer is \"circular reasoning\", model is NOT CORRECT\n",
        "print(tot_prompt_5(input_text=\n",
        "             \"\"\"\n",
        "             America is the best place to live, because it's better than any other country.\n",
        "             \"\"\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zV-EXG5-IEKq",
        "outputId": "dcdf8a02-d9ca-410f-ec75-e19b316360cc"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here are the identified fallacies separated by ';':\n",
            "\n",
            "False dichotomy; False analogy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The answer is \"no fallacy\", model is NOT CORRECT\n",
        "print(tot_prompt_5(input_text=\n",
        "             \"\"\"\n",
        "             The sea-ice loss is President Vladimir Putin' s gain.\n",
        "             Already the largest country on the planet, Russia stands to gain\n",
        "             access to shipping routes and energy reserves, and a strategic\n",
        "             military advantage from the opening of the Arctic. Along the Russian\n",
        "             coastline, which makes up more than half the Arctic total, winds\n",
        "             and currents push old ice away from potential shipping lanes and\n",
        "             prevent the build-up of thicker, multi-year ice that would leave\n",
        "             other parts of the Arctic impassable for longer periods.\n",
        "             \"\"\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FACNXOBKIGoc",
        "outputId": "cb8e68e5-fe44-4103-bdc1-a52ab5dc6adb"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here are the identified fallacies separated by ';':\n",
            "\n",
            "guilt by association; hasty generalization\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}