{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "469c1696e7914f8e89789b6b2fe388ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_15fff023af6345b19dc5efa8f8eed163",
              "IPY_MODEL_d6931c9af3824bd9b74e44df43cf765b",
              "IPY_MODEL_c9149abe62b043e9a165447371c21b07"
            ],
            "layout": "IPY_MODEL_51bdc824bc5847978785f7b80538a43f"
          }
        },
        "15fff023af6345b19dc5efa8f8eed163": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1563d88f400d451da7d1f99dbdf73b1c",
            "placeholder": "​",
            "style": "IPY_MODEL_adbd99a0b48e4b07979927e384a1450e",
            "value": "model.safetensors: 100%"
          }
        },
        "d6931c9af3824bd9b74e44df43cf765b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a9657815c9614e7b9972251b926ecc87",
            "max": 5702746403,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5b8dca064cc446bc82f4ffaea6b36263",
            "value": 5702746403
          }
        },
        "c9149abe62b043e9a165447371c21b07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_60369dffd57f4602ac02f5216e39c78f",
            "placeholder": "​",
            "style": "IPY_MODEL_a35533db35754efc9a50f4ff969c0e9a",
            "value": " 5.70G/5.70G [00:50&lt;00:00, 179MB/s]"
          }
        },
        "51bdc824bc5847978785f7b80538a43f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1563d88f400d451da7d1f99dbdf73b1c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "adbd99a0b48e4b07979927e384a1450e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a9657815c9614e7b9972251b926ecc87": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b8dca064cc446bc82f4ffaea6b36263": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "60369dffd57f4602ac02f5216e39c78f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a35533db35754efc9a50f4ff969c0e9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3038722363364595a0634b9fc0c70df9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f2f82a02aa1b402484b2bf3bb4294cf4",
              "IPY_MODEL_71ef02d06cfb4964b709f59dbde04b6e",
              "IPY_MODEL_6e708159cea84fed870aafa0d8cd26b6"
            ],
            "layout": "IPY_MODEL_1fab78030c414d72accc3077a15191ef"
          }
        },
        "f2f82a02aa1b402484b2bf3bb4294cf4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a99728eac79f4f49899b90817ba11b6c",
            "placeholder": "​",
            "style": "IPY_MODEL_f749addd3061417e9ff988f3b74a17dd",
            "value": "generation_config.json: 100%"
          }
        },
        "71ef02d06cfb4964b709f59dbde04b6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_62d61507f58240249e0a6ff81c3852ce",
            "max": 131,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8bfedb66adfe4bd3afdd21b1256d5587",
            "value": 131
          }
        },
        "6e708159cea84fed870aafa0d8cd26b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7e2adf72ef9f4d689955bb0a5b0887ee",
            "placeholder": "​",
            "style": "IPY_MODEL_d1f2192ab9b74a69ab8fbe8ec3a235a2",
            "value": " 131/131 [00:00&lt;00:00, 7.80kB/s]"
          }
        },
        "1fab78030c414d72accc3077a15191ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a99728eac79f4f49899b90817ba11b6c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f749addd3061417e9ff988f3b74a17dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "62d61507f58240249e0a6ff81c3852ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8bfedb66adfe4bd3afdd21b1256d5587": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7e2adf72ef9f4d689955bb0a5b0887ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1f2192ab9b74a69ab8fbe8ec3a235a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "37f102ccf4fa4a968ecea2c6b686bba8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_99791d558aba49bfbb90859079bb740c",
              "IPY_MODEL_ace4a1f75d6a4005b112139e34c8d9da",
              "IPY_MODEL_346c84edea4b47ec9115ee092d101d03"
            ],
            "layout": "IPY_MODEL_aaf9fe74bd924b98b99b1da0f66002cf"
          }
        },
        "99791d558aba49bfbb90859079bb740c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bdc474c10e094fc8b65b44c4c8c2fa37",
            "placeholder": "​",
            "style": "IPY_MODEL_582b99ae8d204f6a9d32c64c852da6a4",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "ace4a1f75d6a4005b112139e34c8d9da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fdd64ae68bf24548b45727046fc79a2f",
            "max": 51052,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_28eb46b4c24b49aabeb88e68178d942c",
            "value": 51052
          }
        },
        "346c84edea4b47ec9115ee092d101d03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_50bcb942e54d4941aec68b070f900fe9",
            "placeholder": "​",
            "style": "IPY_MODEL_9b25e570262e415e8f57e5754d4a527f",
            "value": " 51.1k/51.1k [00:00&lt;00:00, 3.09MB/s]"
          }
        },
        "aaf9fe74bd924b98b99b1da0f66002cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bdc474c10e094fc8b65b44c4c8c2fa37": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "582b99ae8d204f6a9d32c64c852da6a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fdd64ae68bf24548b45727046fc79a2f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "28eb46b4c24b49aabeb88e68178d942c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "50bcb942e54d4941aec68b070f900fe9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b25e570262e415e8f57e5754d4a527f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "981eeb6b35504b5197a8f2ecdf3c945c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cdb4e987c7334aa4888fefc1f2604971",
              "IPY_MODEL_bf2e99da529b4938ae92cb94c4e1d2e7",
              "IPY_MODEL_f4bb2a3b90f54f8fa3992259a54c27b3"
            ],
            "layout": "IPY_MODEL_42e3ca02741949ce943bc8eb4255f32b"
          }
        },
        "cdb4e987c7334aa4888fefc1f2604971": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_136bc6328ce3465580344fc74277b671",
            "placeholder": "​",
            "style": "IPY_MODEL_aad09fc6978a4f6f8fe1719f32a2a7fc",
            "value": "tokenizer.json: 100%"
          }
        },
        "bf2e99da529b4938ae92cb94c4e1d2e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8635fa235f7d424bb65b6656491d14b0",
            "max": 9085698,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3b0acd769be24338bc2c04e036723fb6",
            "value": 9085698
          }
        },
        "f4bb2a3b90f54f8fa3992259a54c27b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_133b1f2cf72641519e36370d9813b1db",
            "placeholder": "​",
            "style": "IPY_MODEL_44ab116ce4a6464abfc7dc6b5c360b0a",
            "value": " 9.09M/9.09M [00:00&lt;00:00, 13.0MB/s]"
          }
        },
        "42e3ca02741949ce943bc8eb4255f32b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "136bc6328ce3465580344fc74277b671": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aad09fc6978a4f6f8fe1719f32a2a7fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8635fa235f7d424bb65b6656491d14b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b0acd769be24338bc2c04e036723fb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "133b1f2cf72641519e36370d9813b1db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "44ab116ce4a6464abfc7dc6b5c360b0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "61542983bdac4c85bdf7471450f65e00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b6bf0280354048039b08f1ebcd5d7851",
              "IPY_MODEL_daee276375e74b4bb10cbe4b6a6ded83",
              "IPY_MODEL_0dcdae99d2c24a0b923f9b543ea1b405"
            ],
            "layout": "IPY_MODEL_59e5273c1ad34f28a830fe1f45affdfc"
          }
        },
        "b6bf0280354048039b08f1ebcd5d7851": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_63ce00e27a1b4419ba1bd8b17ca1d39e",
            "placeholder": "​",
            "style": "IPY_MODEL_d495856269c647a48d624b0fe8db07f9",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "daee276375e74b4bb10cbe4b6a6ded83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b07df9b4f25b43e2ae6c89a41c602cd5",
            "max": 459,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b66a15671c2748079098e1dc06b64b8d",
            "value": 459
          }
        },
        "0dcdae99d2c24a0b923f9b543ea1b405": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_67d9c6921beb414c9b09e7fa193d7281",
            "placeholder": "​",
            "style": "IPY_MODEL_4053082cc00547b0911688c9fb225016",
            "value": " 459/459 [00:00&lt;00:00, 18.5kB/s]"
          }
        },
        "59e5273c1ad34f28a830fe1f45affdfc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63ce00e27a1b4419ba1bd8b17ca1d39e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d495856269c647a48d624b0fe8db07f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b07df9b4f25b43e2ae6c89a41c602cd5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b66a15671c2748079098e1dc06b64b8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "67d9c6921beb414c9b09e7fa193d7281": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4053082cc00547b0911688c9fb225016": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Code to deploy Llama3: https://www.analyticsvidhya.com/blog/2024/04/how-to-run-llama-3-locally/"
      ],
      "metadata": {
        "id": "q7tlS5spaWRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install Dependencies"
      ],
      "metadata": {
        "id": "Hy0vG_pmOY_4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7NBDgf_pIfZS",
        "outputId": "a2a17ad1-9b5f-47d5-e93a-a2c5ab250b2b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers==4.40.0 in /usr/local/lib/python3.10/dist-packages (4.40.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.40.0) (3.14.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers==4.40.0) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.40.0) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.40.0) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.40.0) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.40.0) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.40.0) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers==4.40.0) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.40.0) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.40.0) (4.66.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.40.0) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.40.0) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.40.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.40.0) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.40.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.40.0) (2024.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install -U \"transformers==4.40.0\" --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -i https://pypi.org/simple/ bitsandbytes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Pi4LjWqKKFT",
        "outputId": "360652e0-f896-41fa-818d-a711df68b6f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple/\n",
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.10/dist-packages (0.43.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (2.2.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (1.25.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->bitsandbytes) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->bitsandbytes) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install accelerate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uGTGGVCqKMCB",
        "outputId": "24878b64-46ca-44be-bdf6-ac252a255c78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.30.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.2.1+cu121)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download Llama 3"
      ],
      "metadata": {
        "id": "kx8LzAiDOhy7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "import torch\n",
        "\n",
        "model_id = \"unsloth/llama-3-8b-Instruct-bnb-4bit\"\n",
        "\n",
        "pipeline = transformers.pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model_id,\n",
        "    model_kwargs={\n",
        "        \"torch_dtype\": torch.float16,\n",
        "        \"quantization_config\": {\"load_in_4bit\": True},\n",
        "        \"low_cpu_mem_usage\": True,\n",
        "    },\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371,
          "referenced_widgets": [
            "469c1696e7914f8e89789b6b2fe388ea",
            "15fff023af6345b19dc5efa8f8eed163",
            "d6931c9af3824bd9b74e44df43cf765b",
            "c9149abe62b043e9a165447371c21b07",
            "51bdc824bc5847978785f7b80538a43f",
            "1563d88f400d451da7d1f99dbdf73b1c",
            "adbd99a0b48e4b07979927e384a1450e",
            "a9657815c9614e7b9972251b926ecc87",
            "5b8dca064cc446bc82f4ffaea6b36263",
            "60369dffd57f4602ac02f5216e39c78f",
            "a35533db35754efc9a50f4ff969c0e9a",
            "3038722363364595a0634b9fc0c70df9",
            "f2f82a02aa1b402484b2bf3bb4294cf4",
            "71ef02d06cfb4964b709f59dbde04b6e",
            "6e708159cea84fed870aafa0d8cd26b6",
            "1fab78030c414d72accc3077a15191ef",
            "a99728eac79f4f49899b90817ba11b6c",
            "f749addd3061417e9ff988f3b74a17dd",
            "62d61507f58240249e0a6ff81c3852ce",
            "8bfedb66adfe4bd3afdd21b1256d5587",
            "7e2adf72ef9f4d689955bb0a5b0887ee",
            "d1f2192ab9b74a69ab8fbe8ec3a235a2",
            "37f102ccf4fa4a968ecea2c6b686bba8",
            "99791d558aba49bfbb90859079bb740c",
            "ace4a1f75d6a4005b112139e34c8d9da",
            "346c84edea4b47ec9115ee092d101d03",
            "aaf9fe74bd924b98b99b1da0f66002cf",
            "bdc474c10e094fc8b65b44c4c8c2fa37",
            "582b99ae8d204f6a9d32c64c852da6a4",
            "fdd64ae68bf24548b45727046fc79a2f",
            "28eb46b4c24b49aabeb88e68178d942c",
            "50bcb942e54d4941aec68b070f900fe9",
            "9b25e570262e415e8f57e5754d4a527f",
            "981eeb6b35504b5197a8f2ecdf3c945c",
            "cdb4e987c7334aa4888fefc1f2604971",
            "bf2e99da529b4938ae92cb94c4e1d2e7",
            "f4bb2a3b90f54f8fa3992259a54c27b3",
            "42e3ca02741949ce943bc8eb4255f32b",
            "136bc6328ce3465580344fc74277b671",
            "aad09fc6978a4f6f8fe1719f32a2a7fc",
            "8635fa235f7d424bb65b6656491d14b0",
            "3b0acd769be24338bc2c04e036723fb6",
            "133b1f2cf72641519e36370d9813b1db",
            "44ab116ce4a6464abfc7dc6b5c360b0a",
            "61542983bdac4c85bdf7471450f65e00",
            "b6bf0280354048039b08f1ebcd5d7851",
            "daee276375e74b4bb10cbe4b6a6ded83",
            "0dcdae99d2c24a0b923f9b543ea1b405",
            "59e5273c1ad34f28a830fe1f45affdfc",
            "63ce00e27a1b4419ba1bd8b17ca1d39e",
            "d495856269c647a48d624b0fe8db07f9",
            "b07df9b4f25b43e2ae6c89a41c602cd5",
            "b66a15671c2748079098e1dc06b64b8d",
            "67d9c6921beb414c9b09e7fa193d7281",
            "4053082cc00547b0911688c9fb225016"
          ]
        },
        "id": "w6rEsdO_IxPV",
        "outputId": "f46f446f-92bf-4345-e230-8c5cf11e2f14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/quantizers/auto.py:159: UserWarning: You passed `quantization_config` or equivalent parameters to `from_pretrained` but the model you're loading already has a `quantization_config` attribute. The `quantization_config` from the model will be used.\n",
            "  warnings.warn(warning_msg)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/5.70G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "469c1696e7914f8e89789b6b2fe388ea"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/131 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3038722363364595a0634b9fc0c70df9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/51.1k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "37f102ccf4fa4a968ecea2c6b686bba8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "981eeb6b35504b5197a8f2ecdf3c945c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/459 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "61542983bdac4c85bdf7471450f65e00"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Query Llama 3"
      ],
      "metadata": {
        "id": "KnysTccigPk2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [\n",
        "    {\"role\"   : \"system\",\n",
        "     \"content\": \"You are a helpful assistant!\"},\n",
        "    {\"role\"   : \"user\",\n",
        "     \"content\": \"\"\"What is the meaning of life?\"\"\"},\n",
        "]\n",
        "\n",
        "prompt = pipeline.tokenizer.apply_chat_template(\n",
        "        messages,\n",
        "        tokenize=False,\n",
        "        add_generation_prompt=True\n",
        ")\n",
        "\n",
        "terminators = [\n",
        "    pipeline.tokenizer.eos_token_id,\n",
        "    pipeline.tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
        "]\n",
        "\n",
        "outputs = pipeline(\n",
        "    prompt,\n",
        "    max_new_tokens=256,\n",
        "    eos_token_id=terminators,\n",
        "    do_sample=True,\n",
        "    temperature=0.6,\n",
        "    top_p=0.9,\n",
        ")\n",
        "\n",
        "print(outputs[0][\"generated_text\"][len(prompt):])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1xotzkqDIzPN",
        "outputId": "6c0724d3-84b1-4d66-fc1d-26491bba1730"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What a profound and complex question! The meaning of life is a topic that has been debated and explored by philosophers, scientists, and thinkers across various cultures and civilizations. While there is no one definitive answer, I can provide some insights and perspectives that might help shed light on this question.\n",
            "\n",
            "The meaning of life is often understood as the purpose, significance, or reason for which an individual exists. It can be seen as a personal, subjective experience that is unique to each individual. For some, the meaning of life might be found in their relationships, personal achievements, or contributions to society. For others, it might be a sense of spiritual connection, a pursuit of knowledge, or a desire to make a positive impact on the world.\n",
            "\n",
            "Philosophers have proposed various theories about the meaning of life. Some argue that it is inherent in the human condition, while others believe it is something that must be discovered or created. Here are a few examples:\n",
            "\n",
            "1. **Hedonic utilitarianism**: This perspective, advocated by philosophers like Jeremy Bentham and John Stuart Mill, suggests that the meaning of life is to maximize happiness and minimize suffering.\n",
            "2. **Existentialism**: Thinkers like Jean-Paul Sartre and Martin Heidegger propose that the meaning of life is\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Just the names seperated by ; and nothing else in your answer!"
      ],
      "metadata": {
        "id": "MTEOLClngLQS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [\n",
        "    {\"role\"   : \"system\",\n",
        "     \"content\": \"You are a helpful assistant!\"},\n",
        "    {\"role\"   : \"user\",\n",
        "     \"content\": \"\"\"Please name me the types of fallacy that occur in this text.\n",
        "     These are possible fallacies:\n",
        "     (Fallacy of Credibility: Abusive, Ad Hominem, Ad Populum, Appeal to False Authority,\n",
        "     Appeal to Nature, Appeal to Tradition, Guilt by Association, Tu Quoque;\n",
        "     Fallacy of Logic: Causal Oversimplification, Circular Reasoning, Equivocation, False Analogy False, Causality, False Dilemma,\n",
        "     Hasty Generalization, Slippery Slope, Straw Man, Fallacy of Division;\n",
        "     Appeal to Emotion: Appeal to Positive Emotion, Appeal to Anger, Appeal to Fear, Appeal to Pity, Appeal to Ridicule,\n",
        "     Appeal to Worse Problem)\n",
        "\n",
        "     Let’s think step by step:\n",
        "     America is the best place to live, because it's better than any other country\n",
        "     \"\"\"},\n",
        "]\n",
        "\n",
        "prompt = pipeline.tokenizer.apply_chat_template(\n",
        "        messages,\n",
        "        tokenize=False,\n",
        "        add_generation_prompt=True\n",
        ")\n",
        "\n",
        "terminators = [\n",
        "    pipeline.tokenizer.eos_token_id,\n",
        "    pipeline.tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
        "]\n",
        "\n",
        "outputs = pipeline(\n",
        "    prompt,\n",
        "    max_new_tokens=512,\n",
        "    eos_token_id=terminators,\n",
        "    do_sample=True,\n",
        "    temperature=0.6,\n",
        "    top_p=0.9,\n",
        ")\n",
        "\n",
        "print(outputs[0][\"generated_text\"][len(prompt):])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CWeoOFzAbf2h",
        "outputId": "3f7ac179-7100-4b1b-b9aa-4f71cf74a5a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What a great text to analyze!\n",
            "\n",
            "After examining the text, I've identified the following fallacies:\n",
            "\n",
            "1. **Appeal to Tradition**: The statement assumes that America is the best place to live simply because it's been considered so by many people in the past, without providing any concrete evidence or reasoning to support this claim.\n",
            "2. **False Dilemma**: The statement presents a binary choice, implying that there's only one \"best\" place to live, which is not necessarily true. There might be other countries that excel in different areas, making them suitable for different individuals or purposes.\n",
            "\n",
            "These fallacies occur because the statement relies on a simplistic and unsubstantiated claim, rather than providing a well-reasoned argument or evidence to support its assertion.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [\n",
        "    {\"role\"   : \"system\",\n",
        "     \"content\": \"You are a helpful assistant!\"},\n",
        "    {\"role\"   : \"user\",\n",
        "     \"content\": \"\"\"\n",
        "     Identify the types of fallacies present in the given text. Potential fallacies include:\n",
        "\n",
        "Fallacy of Credibility: Abusive; Ad Hominem; Ad Populum; Appeal to False Authority; Appeal to Nature; Appeal to Tradition; Guilt by Association; Tu Quoque\n",
        "Fallacy of Logic: Causal Oversimplification; Circular Reasoning; Equivocation; False Analogy; False Causality; False Dilemma; Hasty Generalization; Slippery Slope; Straw Man; Fallacy of Division\n",
        "Appeal to Emotion: Appeal to Positive Emotion; Appeal to Anger; Appeal to Fear; Appeal to Pity; Appeal to Ridicule; Appeal to Worse Problem\n",
        "Analyzing the text:\n",
        "\n",
        "\"Every sunrise, the rooster makes a sound. So it is the rooster which makes the sun rise.\"\n",
        "\n",
        "Output just the identified fallacies separated by ;.\n",
        "     \"\"\"},\n",
        "]\n",
        "\n",
        "prompt = pipeline.tokenizer.apply_chat_template(\n",
        "        messages,\n",
        "        tokenize=False,\n",
        "        add_generation_prompt=True\n",
        ")\n",
        "\n",
        "terminators = [\n",
        "    pipeline.tokenizer.eos_token_id,\n",
        "    pipeline.tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
        "]\n",
        "\n",
        "outputs = pipeline(\n",
        "    prompt,\n",
        "    max_new_tokens=512,\n",
        "    eos_token_id=terminators,\n",
        "    do_sample=True,\n",
        "    temperature=0.6,\n",
        "    top_p=0.9,\n",
        ")\n",
        "\n",
        "print(outputs[0][\"generated_text\"][len(prompt):])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F0dIzb8heaZ5",
        "outputId": "f5178df0-307e-433d-b428-9f66c7f014b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "circular reasoning; begging the question; assuming the conclusion\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [\n",
        "    {\"role\"   : \"system\",\n",
        "     \"content\": \"You are a helpful assistant which is an expert in logical fallacies!\"},\n",
        "    {\"role\"   : \"user\",\n",
        "     \"content\": \"\"\"\n",
        "     Identify the types of fallacies present in the given text. Potential fallacies include:\n",
        "\n",
        "slippery slope; thin edge of the wedge; domino fallacy\n",
        "hasty generalization; faulty generalization; fallacy of defective induction\n",
        "false analogy; false equivalency\n",
        "guilt by association; association fallacy; appeal to spite\n",
        "causal oversimplification; complex cause; causal reductionism; root cause fallacy; reduction fallacy\n",
        "ad populum; argumentum ad populum; appeal to (common) belief; appeal to popularity; appeal to the majority; appeal to the masses; argument from consensus; authority of the many; bandwagon fallacy; common belief fallacy; democratic fallacy; mob appeal; truth by association; consensus gentium\n",
        "circular reasoning; circulus in probando; begging the question; assuming the conclusion\n",
        "appeal to fear; argumentum ad passiones; red herring\n",
        "false causality\n",
        "fallacy of division\n",
        "appeal to ridicule; appeal to mockery; ad absurdo; horse laugh\n",
        "appeal to worse problems; not as bad as; fallacy of relative privation\n",
        "abusive ad hominem; argumentum ad hominem\n",
        "appeal to false authority; argument from authority; argumentum ad verecundiam; ad verecundiam\n",
        "appeal to positive emotion; appeal to emotion\n",
        "appeal to nature\n",
        "equivocation\n",
        "appeal to anger\n",
        "false dilemma; false dichotomy; false binary\n",
        "straw man\n",
        "appeal to tradition; argumentum ad antiquitatem; appeal to antiquity; appeal to common practice\n",
        "tu quoque; ad hominem\n",
        "\n",
        "no fallacies is also an option\n",
        "Analyzing the text:\n",
        "\n",
        "\"My father smoked four packs of cigarettes a day from age 14 and lived until the age of 95. So smoking really can’t be that bad for you.\"\n",
        "\n",
        "Output just the identified fallacies with its name separated by ;.\n",
        "     \"\"\"},\n",
        "]\n",
        "\n",
        "prompt = pipeline.tokenizer.apply_chat_template(\n",
        "        messages,\n",
        "        tokenize=False,\n",
        "        add_generation_prompt=True\n",
        ")\n",
        "\n",
        "terminators = [\n",
        "    pipeline.tokenizer.eos_token_id,\n",
        "    pipeline.tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
        "]\n",
        "\n",
        "outputs = pipeline(\n",
        "    prompt,\n",
        "    max_new_tokens=512,\n",
        "    eos_token_id=terminators,\n",
        "    do_sample=True,\n",
        "    temperature=0.6,\n",
        "    top_p=0.9,\n",
        ")\n",
        "\n",
        "print(outputs[0][\"generated_text\"][len(prompt):])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FQEkrlWDhUUu",
        "outputId": "99a92336-4b4d-4a62-975d-f946866d0f7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Appeal to personal experience; Appeal to anecdote; Hasty generalization; False analogy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_to_check = \"My father smoked four packs of cigarettes a day from age 14 and lived until the age of 95. So smoking really can’t be that bad for you.\"\n",
        "\n",
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful assistant which is an expert in detecting logical fallacies!\"},\n",
        "    {\"role\": \"user\", \"content\": \"Identify if this text:\\n\" + text_to_check + \"\\ncontains the fallacy 'slippery slope'. Here is an example for a slippery slope:\\n\\nIf we ban assault rifles, next they'll ban all guns, and before you know it, we'll be living in a police state. Return 'slippery slope' if it is the case, else return 'no fallacy'.\"},\n",
        "    {\"role\": \"user\", \"content\": \"Identify if this text:\\n\" + text_to_check + \"\\ncontains the fallacy 'hasty generalization'. Here is an example for a hasty generalization:\\n\\nI met two people from New York City, and both were rude. Therefore, all New Yorkers are rude. Return 'hasty generalization' if it is the case, else return 'no fallacy'.\"},\n",
        "    {\"role\": \"user\", \"content\": \"Identify if this text:\\n\" + text_to_check + \"\\ncontains the fallacy 'false analogy'. Here is an example for a false analogy:\\n\\nComparing buying a car to choosing a spouse is a false analogy because the two situations are vastly different. Return 'false analogy' if it is the case, else return 'no fallacy'.\"},\n",
        "    {\"role\": \"user\", \"content\": \"Identify if this text:\\n\" + text_to_check + \"\\ncontains the fallacy 'guilt by association'. Here is an example for guilt by association:\\n\\nYou shouldn't listen to John's opinion on politics; he's friends with several criminals. Return 'guilt by association' if it is the case, else return 'no fallacy'.\"},\n",
        "    {\"role\": \"user\", \"content\": \"Identify if this text:\\n\" + text_to_check + \"\\ncontains the fallacy 'causal oversimplification'. Here is an example for causal oversimplification:\\n\\nThe rise in crime rates is due to violent video games; therefore, banning them will solve the problem. Return 'causal oversimplification' if it is the case, else return 'no fallacy'.\"},\n",
        "    {\"role\": \"user\", \"content\": \"Identify if this text:\\n\" + text_to_check + \"\\ncontains the fallacy 'ad populum'. Here is an example for ad populum:\\n\\nEveryone is buying the new smartphone, so it must be the best one on the market. Return 'ad populum' if it is the case, else return 'no fallacy'.\"},\n",
        "    {\"role\": \"user\", \"content\": \"Identify if this text:\\n\" + text_to_check + \"\\ncontains the fallacy 'circular reasoning'. Here is an example for circular reasoning:\\n\\nThe Bible is the word of God because God says it is in the Bible. Return 'circular reasoning' if it is the case, else return 'no fallacy'.\"},\n",
        "    {\"role\": \"user\", \"content\": \"Identify if this text:\\n\" + text_to_check + \"\\ncontains the fallacy 'appeal to fear'. Here is an example for appeal to fear:\\n\\nIf you don't vote for me, your taxes will skyrocket and crime will run rampant. Return 'appeal to fear' if it is the case, else return 'no fallacy'.\"},\n",
        "    {\"role\": \"user\", \"content\": \"Identify if this text:\\n\" + text_to_check + \"\\ncontains the fallacy 'false causality'. Here is an example for false causality:\\n\\nEvery time I wash my car, it rains. Therefore, washing my car causes rain. Return 'false causality' if it is the case, else return 'no fallacy'.\"},\n",
        "    {\"role\": \"user\", \"content\": \"Identify if this text:\\n\" + text_to_check + \"\\ncontains the fallacy 'fallacy of division'. Here is an example for fallacy of division:\\n\\nThat company is profitable, so all of its employees must be well-paid. Return 'fallacy of division' if it is the case, else return 'no fallacy'.\"},\n",
        "    {\"role\": \"user\", \"content\": \"Identify if this text:\\n\" + text_to_check + \"\\ncontains the fallacy 'appeal to ridicule'. Here is an example for appeal to ridicule:\\n\\nYou shouldn't listen to Mary's argument about climate change; she believes the Earth is flat! Return 'appeal to ridicule' if it is the case, else return 'no fallacy'.\"},\n",
        "    {\"role\": \"user\", \"content\": \"Identify if this text:\\n\" + text_to_check + \"\\ncontains the fallacy 'appeal to worse problems'. Here is an example for appeal to worse problems:\\n\\nWhy are we worrying about pollution when there are children starving in the world? Return 'appeal to worse problems' if it is the case, else return 'no fallacy'.\"},\n",
        "    {\"role\": \"user\", \"content\": \"Identify if this text:\\n\" + text_to_check + \"\\ncontains the fallacy 'abusive ad hominem'. Here is an example for abusive ad hominem:\\n\\nYou can't trust anything Tom says; he's just a loser. Return 'abusive ad hominem' if it is the case, else return 'no fallacy'.\"},\n",
        "    {\"role\": \"user\", \"content\": \"Identify if this text:\\n\" + text_to_check + \"\\ncontains the fallacy 'appeal to false authority'. Here is an example for appeal to false authority:\\n\\nMy doctor says that smoking is good for you, so it must be true. Return 'appeal to false authority' if it is the case, else return 'no fallacy'.\"},\n",
        "    {\"role\": \"user\", \"content\": \"Identify if this text:\\n\" + text_to_check + \"\\ncontains the fallacy 'appeal to positive emotion'. Here is an example for appeal to positive emotion:\\n\\nIf you care about the environment, you'll buy this eco-friendly product. Return 'appeal to positive emotion' if it is the case, else return 'no fallacy'.\"},\n",
        "    {\"role\": \"user\", \"content\": \"Identify if this text:\\n\" + text_to_check + \"\\ncontains the fallacy 'appeal to nature'. Here is an example for appeal to nature:\\n\\nNatural remedies are always better than pharmaceutical drugs. Return 'appeal to nature' if it is the case, else return 'no fallacy'.\"},\n",
        "    {\"role\": \"user\", \"content\": \"Identify if this text:\\n\" + text_to_check + \"\\ncontains the fallacy 'equivocation'. Here is an example for equivocation:\\n\\nThe sign said 'Fine for parking here,' so I thought it would be fine to park there. Return 'equivocation' if it is the case, else return 'no fallacy'.\"},\n",
        "    {\"role\": \"user\", \"content\": \"Identify if this text:\\n\" + text_to_check + \"\\ncontains the fallacy 'appeal to anger'. Here is an example for appeal to anger:\\n\\nYou wouldn't want to be a coward, would you? Then you better join the military! Return 'appeal to anger' if it is the case, else return 'no fallacy'.\"},\n",
        "    {\"role\": \"user\", \"content\": \"Identify if this text:\\n\" + text_to_check + \"\\ncontains the fallacy 'false dilemma'. Here is an example for false dilemma:\\n\\nEither we ban all guns or we'll continue to have mass shootings. Return 'false dilemma' if it is the case, else return 'no fallacy'.\"},\n",
        "    {\"role\": \"user\", \"content\": \"Identify if this text:\\n\" + text_to_check + \"\\ncontains the fallacy 'straw man'. Here is an example for straw man:\\n\\nOpponents of gun control argue that we should give guns to everyone, including criminals and children. Return 'straw man' if it is the case, else return 'no fallacy'.\"},\n",
        "    {\"role\": \"user\", \"content\": \"Identify if this text:\\n\" + text_to_check + \"\\ncontains the fallacy 'appeal to tradition'. Here is an example for appeal to tradition:\\n\\nWe should continue to use fossil fuels because that's how we've always done it. Return 'appeal to tradition' if it is the case, else return 'no fallacy'.\"},\n",
        "    {\"role\": \"user\", \"content\": \"Identify if this text:\\n\" + text_to_check + \"\\ncontains the fallacy 'tu quoque'. Here is an example for tu quoque:\\n\\nYou say I shouldn't smoke, but I've seen you smoke before! Return 'tu quoque' if it is the case, else return 'no fallacy'.\"}\n",
        "]\n",
        "\n",
        "prompt = pipeline.tokenizer.apply_chat_template(\n",
        "        messages,\n",
        "        tokenize=False,\n",
        "        add_generation_prompt=True\n",
        ")\n",
        "\n",
        "terminators = [\n",
        "    pipeline.tokenizer.eos_token_id,\n",
        "    pipeline.tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
        "]\n",
        "\n",
        "outputs = pipeline(\n",
        "    prompt,\n",
        "    max_new_tokens=512,\n",
        "    eos_token_id=terminators,\n",
        "    do_sample=True,\n",
        "    temperature=0.6,\n",
        "    top_p=0.9,\n",
        ")\n",
        "\n",
        "print(outputs[0][\"generated_text\"][len(prompt):])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e4YU1Um-m8_R",
        "outputId": "d6dcc900-9e0a-4088-c3a5-cc86cd205c46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The text does not contain any of the fallacies mentioned. The text is a simple anecdote about the author's father smoking heavily and living a long life, and the conclusion drawn from this is that smoking can't be that bad for you. This is a weak and anecdotal argument, but it does not contain any specific fallacies.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fallacies = []\n",
        "\n",
        "# Slippery Slope\n",
        "slippery_slope_prompt = pipeline.tokenizer.apply_chat_template(\n",
        "    [\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant which is an expert in detecting logical fallacies!\"},\n",
        "        {\"role\": \"user\", \"content\": \"Identify if this text:\\n\" + text_to_check + \"\\ncontains the fallacy 'slippery slope'. Here is an example for a slippery slope:\\n\\nIf we ban assault rifles, next they'll ban all guns, and before you know it, we'll be living in a police state. Return 'slippery slope' if it is the case, else return 'no fallacy'.\"}\n",
        "    ],\n",
        "    tokenize=False,\n",
        "    add_generation_prompt=True\n",
        ")\n",
        "\n",
        "outputs = pipeline(\n",
        "    slippery_slope_prompt,\n",
        "    max_new_tokens=512,\n",
        "    eos_token_id=terminators,\n",
        "    do_sample=True,\n",
        "    temperature=0.6,\n",
        "    top_p=0.9,\n",
        ")\n",
        "fallacies.append(outputs[0][\"generated_text\"][len(slippery_slope_prompt):])\n",
        "\n",
        "# Hasty Generalization\n",
        "hasty_generalization_prompt = pipeline.tokenizer.apply_chat_template(\n",
        "    [\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant which is an expert in detecting logical fallacies!\"},\n",
        "        {\"role\": \"user\", \"content\": \"Identify if this text:\\n\" + text_to_check + \"\\ncontains the fallacy 'hasty generalization'. Here is an example for a hasty generalization:\\n\\nI met two people from New York City, and both were rude. Therefore, all New Yorkers are rude. Return 'hasty generalization' if it is the case, else return 'no fallacy'.\"}\n",
        "    ],\n",
        "    tokenize=False,\n",
        "    add_generation_prompt=True\n",
        ")\n",
        "\n",
        "outputs = pipeline(\n",
        "    hasty_generalization_prompt,\n",
        "    max_new_tokens=512,\n",
        "    eos_token_id=terminators,\n",
        "    do_sample=True,\n",
        "    temperature=0.6,\n",
        "    top_p=0.9,\n",
        ")\n",
        "fallacies.append(outputs[0][\"generated_text\"][len(hasty_generalization_prompt):])\n",
        "\n",
        "# False Analogy\n",
        "false_analogy_prompt = pipeline.tokenizer.apply_chat_template(\n",
        "    [\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant which is an expert in detecting logical fallacies!\"},\n",
        "        {\"role\": \"user\", \"content\": \"Identify if this text:\\n\" + text_to_check + \"\\ncontains the fallacy 'false analogy'. Here is an example for a false analogy:\\n\\nComparing buying a car to choosing a spouse is a false analogy because the two situations are vastly different. Return 'false analogy' if it is the case, else return 'no fallacy'.\"}\n",
        "    ],\n",
        "    tokenize=False,\n",
        "    add_generation_prompt=True\n",
        ")\n",
        "\n",
        "outputs = pipeline(\n",
        "    false_analogy_prompt,\n",
        "    max_new_tokens=512,\n",
        "    eos_token_id=terminators,\n",
        "    do_sample=True,\n",
        "    temperature=0.6,\n",
        "    top_p=0.9,\n",
        ")\n",
        "fallacies.append(outputs[0][\"generated_text\"][len(false_analogy_prompt):])\n",
        "\n",
        "# Guilt by Association\n",
        "guilt_by_association_prompt = pipeline.tokenizer.apply_chat_template(\n",
        "    [\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant which is an expert in detecting logical fallacies!\"},\n",
        "        {\"role\": \"user\", \"content\": \"Identify if this text:\\n\" + text_to_check + \"\\ncontains the fallacy 'guilt by association'. Here is an example for guilt by association:\\n\\nYou shouldn't listen to John's opinion on politics; he's friends with several criminals. Return 'guilt by association' if it is the case, else return 'no fallacy'.\"}\n",
        "    ],\n",
        "    tokenize=False,\n",
        "    add_generation_prompt=True\n",
        ")\n",
        "\n",
        "outputs = pipeline(\n",
        "    guilt_by_association_prompt,\n",
        "    max_new_tokens=512,\n",
        "    eos_token_id=terminators,\n",
        "    do_sample=True,\n",
        "    temperature=0.6,\n",
        "    top_p=0.9,\n",
        ")\n",
        "fallacies.append(outputs[0][\"generated_text\"][len(guilt_by_association_prompt):])\n",
        "\n",
        "# Causal Oversimplification\n",
        "causal_oversimplification_prompt = pipeline.tokenizer.apply_chat_template(\n",
        "    [\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant which is an expert in detecting logical fallacies!\"},\n",
        "        {\"role\": \"user\", \"content\": \"Identify if this text:\\n\" + text_to_check + \"\\ncontains the fallacy 'causal oversimplification'. Here is an example for causal oversimplification:\\n\\nThe rise in crime rates is due to violent video games; therefore, banning them will solve the problem. Return 'causal oversimplification' if it is the case, else return 'no fallacy'.\"}\n",
        "    ],\n",
        "    tokenize=False,\n",
        "    add_generation_prompt=True\n",
        ")\n",
        "\n",
        "outputs = pipeline(\n",
        "    causal_oversimplification_prompt,\n",
        "    max_new_tokens=512,\n",
        "    eos_token_id=terminators,\n",
        "    do_sample=True,\n",
        "    temperature=0.6,\n",
        "    top_p=0.9,\n",
        ")\n",
        "fallacies.append(outputs[0][\"generated_text\"][len(causal_oversimplification_prompt):])\n",
        "\n",
        "# Ad Populum\n",
        "ad_populum_prompt = pipeline.tokenizer.apply_chat_template(\n",
        "    [\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant which is an expert in detecting logical fallacies!\"},\n",
        "        {\"role\": \"user\", \"content\": \"Identify if this text:\\n\" + text_to_check + \"\\ncontains the fallacy 'ad populum'. Here is an example for ad populum:\\n\\nEveryone is buying the new smartphone, so it must be the best one on the market. Return 'ad populum' if it is the case, else return 'no fallacy'.\"}\n",
        "    ],\n",
        "    tokenize=False,\n",
        "    add_generation_prompt=True\n",
        ")\n",
        "\n",
        "outputs = pipeline(\n",
        "    ad_populum_prompt,\n",
        "    max_new_tokens=512,\n",
        "    eos_token_id=terminators,\n",
        "    do_sample=True,\n",
        "    temperature=0.6,\n",
        "    top_p=0.9,\n",
        ")\n",
        "fallacies.append(outputs[0][\"generated_text\"][len(ad_populum_prompt):])\n",
        "\n",
        "# Circular Reasoning\n",
        "circular_reasoning_prompt = pipeline.tokenizer.apply_chat_template(\n",
        "    [\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant which is an expert in detecting logical fallacies!\"},\n",
        "        {\"role\": \"user\", \"content\": \"Identify if this text:\\n\" + text_to_check + \"\\ncontains the fallacy 'circular reasoning'. Here is an example for circular reasoning:\\n\\nThe Bible is the word of God because God says it is in the Bible. Return 'circular reasoning' if it is the case, else return 'no fallacy'.\"}\n",
        "    ],\n",
        "    tokenize=False,\n",
        "    add_generation_prompt=True\n",
        ")\n",
        "\n",
        "outputs = pipeline(\n",
        "    circular_reasoning_prompt,\n",
        "    max_new_tokens=512,\n",
        "    eos_token_id=terminators,\n",
        "    do_sample=True,\n",
        "    temperature=0.6,\n",
        "    top_p=0.9,\n",
        ")\n",
        "fallacies.append(outputs[0][\"generated_text\"][len(circular_reasoning_prompt):])\n",
        "\n",
        "# Appeal to Fear\n",
        "appeal_to_fear_prompt = pipeline.tokenizer.apply_chat_template(\n",
        "    [\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant which is an expert in detecting logical fallacies!\"},\n",
        "        {\"role\": \"user\", \"content\": \"Identify if this text:\\n\" + text_to_check + \"\\ncontains the fallacy 'appeal to fear'. Here is an example for appeal to fear:\\n\\nIf you don't vote for me, your taxes will skyrocket and crime will run rampant. Return 'appeal to fear' if it is the case, else return 'no fallacy'.\"}\n",
        "    ],\n",
        "    tokenize=False,\n",
        "    add_generation_prompt=True\n",
        ")\n",
        "\n",
        "outputs = pipeline(\n",
        "    appeal_to_fear_prompt,\n",
        "    max_new_tokens=512,\n",
        "    eos_token_id=terminators,\n",
        "    do_sample=True,\n",
        "    temperature=0.6,\n",
        "    top_p=0.9,\n",
        ")\n",
        "fallacies.append(outputs[0][\"generated_text\"][len(appeal_to_fear_prompt):])\n",
        "\n",
        "# False Causality\n",
        "false_causality_prompt = pipeline.tokenizer.apply_chat_template(\n",
        "    [\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant which is an expert in detecting logical fallacies!\"},\n",
        "        {\"role\": \"user\", \"content\": \"Identify if this text:\\n\" + text_to_check + \"\\ncontains the fallacy 'false causality'. Here is an example for false causality:\\n\\nEvery time I wash my car, it rains. Therefore, washing my car causes rain. Return 'false causality' if it is the case, else return 'no fallacy'.\"}\n",
        "    ],\n",
        "    tokenize=False,\n",
        "    add_generation_prompt=True\n",
        ")\n",
        "\n",
        "outputs = pipeline(\n",
        "    false_causality_prompt,\n",
        "    max_new_tokens=512,\n",
        "    eos_token_id=terminators,\n",
        "    do_sample=True,\n",
        "    temperature=0.6,\n",
        "    top_p=0.9,\n",
        ")\n",
        "fallacies.append(outputs[0][\"generated_text\"][len(false_causality_prompt):])\n",
        "\n",
        "# Fallacy of Division\n",
        "fallacy_of_division_prompt = pipeline.tokenizer.apply_chat_template(\n",
        "    [\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant which is an expert in detecting logical fallacies!\"},\n",
        "        {\"role\": \"user\", \"content\": \"Identify if this text:\\n\" + text_to_check + \"\\ncontains the fallacy 'fallacy of division'. Here is an example for fallacy of division:\\n\\nThat company is profitable, so all of its employees must be well-paid. Return 'fallacy of division' if it is the case, else return 'no fallacy'.\"}\n",
        "    ],\n",
        "    tokenize=False,\n",
        "    add_generation_prompt=True\n",
        ")\n",
        "\n",
        "outputs = pipeline(\n",
        "    fallacy_of_division_prompt,\n",
        "    max_new_tokens=512,\n",
        "    eos_token_id=terminators,\n",
        "    do_sample=True,\n",
        "    temperature=0.6,\n",
        "    top_p=0.9,\n",
        ")\n",
        "fallacies.append(outputs[0][\"generated_text\"][len(fallacy_of_division_prompt):])\n",
        "\n",
        "# Appeal to Ridicule\n",
        "appeal_to_ridicule_prompt = pipeline.tokenizer.apply_chat_template(\n",
        "    [\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant which is an expert in detecting logical fallacies!\"},\n",
        "        {\"role\": \"user\", \"content\": \"Identify if this text:\\n\" + text_to_check + \"\\ncontains the fallacy 'appeal to ridicule'. Here is an example for appeal to ridicule:\\n\\nYou shouldn't listen to Mary's argument about climate change; she believes the Earth is flat! Return 'appeal to ridicule' if it is the case, else return 'no fallacy'.\"}\n",
        "    ],\n",
        "    tokenize=False,\n",
        "    add_generation_prompt=True\n",
        ")\n",
        "\n",
        "outputs = pipeline(\n",
        "    appeal_to_ridicule_prompt,\n",
        "    max_new_tokens=512,\n",
        "    eos_token_id=terminators,\n",
        "    do_sample=True,\n",
        "    temperature=0.6,\n",
        "    top_p=0.9,\n",
        ")\n",
        "fallacies.append(outputs[0][\"generated_text\"][len(appeal_to_ridicule_prompt):])\n",
        "\n",
        "# Appeal to Worse Problems\n",
        "appeal_to_worse_problems_prompt = pipeline.tokenizer.apply_chat_template(\n",
        "    [\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant which is an expert in detecting logical fallacies!\"},\n",
        "        {\"role\": \"user\", \"content\": \"Identify if this text:\\n\" + text_to_check + \"\\ncontains the fallacy 'appeal to worse problems'. Here is an example for appeal to worse problems:\\n\\nWhy are we worrying about pollution when there are children starving in the world? Return 'appeal to worse problems' if it is the case, else return 'no fallacy'.\"}\n",
        "    ],\n",
        "    tokenize=False,\n",
        "    add_generation_prompt=True\n",
        ")\n",
        "\n",
        "outputs = pipeline(\n",
        "    appeal_to_worse_problems_prompt,\n",
        "    max_new_tokens=512,\n",
        "    eos_token_id=terminators,\n",
        "    do_sample=True,\n",
        "    temperature=0.6,\n",
        "    top_p=0.9,\n",
        ")\n",
        "fallacies.append(outputs[0][\"generated_text\"][len(appeal_to_worse_problems_prompt):])\n",
        "\n",
        "# Abusive Ad Hominem\n",
        "abusive_ad_hominem_prompt = pipeline.tokenizer.apply_chat_template(\n",
        "    [\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant which is an expert in detecting logical fallacies!\"},\n",
        "        {\"role\": \"user\", \"content\": \"Identify if this text:\\n\" + text_to_check + \"\\ncontains the fallacy 'abusive ad hominem'. Here is an example for abusive ad hominem:\\n\\nYou can't trust anything Tom says; he's just a loser. Return 'abusive ad hominem' if it is the case, else return 'no fallacy'.\"}\n",
        "    ],\n",
        "    tokenize=False,\n",
        "    add_generation_prompt=True\n",
        ")\n",
        "\n",
        "outputs = pipeline(\n",
        "    abusive_ad_hominem_prompt,\n",
        "    max_new_tokens=512,\n",
        "    eos_token_id=terminators,\n",
        "    do_sample=True,\n",
        "    temperature=0.6,\n",
        "    top_p=0.9,\n",
        ")\n",
        "fallacies.append(outputs[0][\"generated_text\"][len(abusive_ad_hominem_prompt):])\n",
        "\n",
        "# Appeal to False Authority\n",
        "appeal_to_false_authority_prompt = pipeline.tokenizer.apply_chat_template(\n",
        "    [\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant which is an expert in detecting logical fallacies!\"},\n",
        "        {\"role\": \"user\", \"content\": \"Identify if this text:\\n\" + text_to_check + \"\\ncontains the fallacy 'appeal to false authority'. Here is an example for appeal to false authority:\\n\\nMy doctor says that smoking is good for you, so it must be true. Return 'appeal to false authority' if it is the case, else return 'no fallacy'.\"}\n",
        "    ],\n",
        "    tokenize=False,\n",
        "    add_generation_prompt=True\n",
        ")\n",
        "\n",
        "outputs = pipeline(\n",
        "    appeal_to_false_authority_prompt,\n",
        "    max_new_tokens=512,\n",
        "    eos_token_id=terminators,\n",
        "    do_sample=True,\n",
        "    temperature=0.6,\n",
        "    top_p=0.9,\n",
        ")\n",
        "fallacies.append(outputs[0][\"generated_text\"][len(appeal_to_false_authority_prompt):])\n",
        "\n",
        "# Appeal to Positive Emotion\n",
        "appeal_to_positive_emotion_prompt = pipeline.tokenizer.apply_chat_template(\n",
        "    [\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant which is an expert in detecting logical fallacies!\"},\n",
        "        {\"role\": \"user\", \"content\": \"Identify if this text:\\n\" + text_to_check + \"\\ncontains the fallacy 'appeal to positive emotion'. Here is an example for appeal to positive emotion:\\n\\nIf you care about the environment, you'll buy this eco-friendly product. Return 'appeal to positive emotion' if it is the case, else return 'no fallacy'.\"}\n",
        "    ],\n",
        "    tokenize=False,\n",
        "    add_generation_prompt=True\n",
        ")\n",
        "\n",
        "outputs = pipeline(\n",
        "    appeal_to_positive_emotion_prompt,\n",
        "    max_new_tokens=512,\n",
        "    eos_token_id=terminators,\n",
        "    do_sample=True,\n",
        "    temperature=0.6,\n",
        "    top_p=0.9,\n",
        ")\n",
        "fallacies.append(outputs[0][\"generated_text\"][len(appeal_to_positive_emotion_prompt):])\n",
        "\n",
        "# Appeal to Nature\n",
        "appeal_to_nature_prompt = pipeline.tokenizer.apply_chat_template(\n",
        "    [\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant which is an expert in detecting logical fallacies!\"},\n",
        "        {\"role\": \"user\", \"content\": \"Identify if this text:\\n\" + text_to_check + \"\\ncontains the fallacy 'appeal to nature'. Here is an example for appeal to nature:\\n\\nNatural remedies are always better than pharmaceutical drugs. Return 'appeal to nature' if it is the case, else return 'no fallacy'.\"}\n",
        "    ],\n",
        "    tokenize=False,\n",
        "    add_generation_prompt=True\n",
        ")\n",
        "\n",
        "outputs = pipeline(\n",
        "    appeal_to_nature_prompt,\n",
        "    max_new_tokens=512,\n",
        "    eos_token_id=terminators,\n",
        "    do_sample=True,\n",
        "    temperature=0.6,\n",
        "    top_p=0.9,\n",
        ")\n",
        "fallacies.append(outputs[0][\"generated_text\"][len(appeal_to_nature_prompt):])\n",
        "\n",
        "# Equivocation\n",
        "equivocation_prompt = pipeline.tokenizer.apply_chat_template(\n",
        "    [\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant which is an expert in detecting logical fallacies!\"},\n",
        "        {\"role\": \"user\", \"content\": \"Identify if this text:\\n\" + text_to_check + \"\\ncontains the fallacy 'equivocation'. Here is an example for equivocation:\\n\\nThe sign said 'Fine for parking here,' so I thought it would be fine to park there. Return 'equivocation' if it is the case, else return 'no fallacy'.\"}\n",
        "    ],\n",
        "    tokenize=False,\n",
        "    add_generation_prompt=True\n",
        ")\n",
        "\n",
        "outputs = pipeline(\n",
        "    equivocation_prompt,\n",
        "    max_new_tokens=512,\n",
        "    eos_token_id=terminators,\n",
        "    do_sample=True,\n",
        "    temperature=0.6,\n",
        "    top_p=0.9,\n",
        ")\n",
        "fallacies.append(outputs[0][\"generated_text\"][len(equivocation_prompt):])\n",
        "\n",
        "# Appeal to Anger\n",
        "appeal_to_anger_prompt = pipeline.tokenizer.apply_chat_template(\n",
        "    [\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant which is an expert in detecting logical fallacies!\"},\n",
        "        {\"role\": \"user\", \"content\": \"Identify if this text:\\n\" + text_to_check + \"\\ncontains the fallacy 'appeal to anger'. Here is an example for appeal to anger:\\n\\nYou wouldn't want to be a coward, would you? Then you better join the military! Return 'appeal to anger' if it is the case, else return 'no fallacy'.\"}\n",
        "    ],\n",
        "    tokenize=False,\n",
        "    add_generation_prompt=True\n",
        ")\n",
        "\n",
        "outputs = pipeline(\n",
        "    appeal_to_anger_prompt,\n",
        "    max_new_tokens=512,\n",
        "    eos_token_id=terminators,\n",
        "    do_sample=True,\n",
        "    temperature=0.6,\n",
        "    top_p=0.9,\n",
        ")\n",
        "fallacies.append(outputs[0][\"generated_text\"][len(appeal_to_anger_prompt):])\n",
        "\n",
        "# False Dilemma\n",
        "false_dilemma_prompt = pipeline.tokenizer.apply_chat_template(\n",
        "    [\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant which is an expert in detecting logical fallacies!\"},\n",
        "        {\"role\": \"user\", \"content\": \"Identify if this text:\\n\" + text_to_check + \"\\ncontains the fallacy 'false dilemma'. Here is an example for false dilemma:\\n\\nEither we ban all guns or we'll continue to have mass shootings. Return 'false dilemma' if it is the case, else return 'no fallacy'.\"}\n",
        "    ],\n",
        "    tokenize=False,\n",
        "    add_generation_prompt=True\n",
        ")\n",
        "\n",
        "outputs = pipeline(\n",
        "    false_dilemma_prompt,\n",
        "    max_new_tokens=512,\n",
        "    eos_token_id=terminators,\n",
        "    do_sample=True,\n",
        "    temperature=0.6,\n",
        "    top_p=0.9,\n",
        ")\n",
        "fallacies.append(outputs[0][\"generated_text\"][len(false_dilemma_prompt):])\n",
        "\n",
        "# Straw Man\n",
        "straw_man_prompt = pipeline.tokenizer.apply_chat_template(\n",
        "    [\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant which is an expert in detecting logical fallacies!\"},\n",
        "        {\"role\": \"user\", \"content\": \"Identify if this text:\\n\" + text_to_check + \"\\ncontains the fallacy 'straw man'. Here is an example for straw man:\\n\\nOpponents of gun control argue that we should give guns to everyone, including criminals and children. Return 'straw man' if it is the case, else return 'no fallacy'.\"}\n",
        "    ],\n",
        "    tokenize=False,\n",
        "    add_generation_prompt=True\n",
        ")\n",
        "\n",
        "outputs = pipeline(\n",
        "    straw_man_prompt,\n",
        "    max_new_tokens=512,\n",
        "    eos_token_id=terminators,\n",
        "    do_sample=True,\n",
        "    temperature=0.6,\n",
        "    top_p=0.9,\n",
        ")\n",
        "fallacies.append(outputs[0][\"generated_text\"][len(straw_man_prompt):])\n",
        "\n",
        "# Appeal to Tradition\n",
        "appeal_to_tradition_prompt = pipeline.tokenizer.apply_chat_template(\n",
        "    [\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant which is an expert in detecting logical fallacies!\"},\n",
        "        {\"role\": \"user\", \"content\": \"Identify if this text:\\n\" + text_to_check + \"\\ncontains the fallacy 'appeal to tradition'. Here is an example for appeal to tradition:\\n\\nWe should continue to use fossil fuels because that's how we've always done it. Return 'appeal to tradition' if it is the case, else return 'no fallacy'.\"}\n",
        "    ],\n",
        "    tokenize=False,\n",
        "    add_generation_prompt=True\n",
        ")\n",
        "\n",
        "outputs = pipeline(\n",
        "    appeal_to_tradition_prompt,\n",
        "    max_new_tokens=512,\n",
        "    eos_token_id=terminators,\n",
        "    do_sample=True,\n",
        "    temperature=0.6,\n",
        "    top_p=0.9,\n",
        ")\n",
        "fallacies.append(outputs[0][\"generated_text\"][len(appeal_to_tradition_prompt):])\n",
        "\n",
        "# Tu Quoque\n",
        "tu_quoque_prompt = pipeline.tokenizer.apply_chat_template(\n",
        "    [\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant which is an expert in detecting logical fallacies!\"},\n",
        "        {\"role\": \"user\", \"content\": \"Identify if this text:\\n\" + text_to_check + \"\\ncontains the fallacy 'tu quoque'. Here is an example for tu quoque:\\n\\nYou say I shouldn't smoke, but I've seen you smoke before! Return 'tu quoque' if it is the case, else return 'no fallacy'.\"}\n",
        "    ],\n",
        "    tokenize=False,\n",
        "    add_generation_prompt=True\n",
        ")\n",
        "\n",
        "outputs = pipeline(\n",
        "    tu_quoque_prompt,\n",
        "    max_new_tokens=512,\n",
        "    eos_token_id=terminators,\n",
        "    do_sample=True,\n",
        "    temperature=0.6,\n",
        "    top_p=0.9,\n",
        ")\n",
        "fallacies.append(outputs[0][\"generated_text\"][len(tu_quoque_prompt):])\n",
        "\n",
        "# Aggregating the results\n",
        "fallacies_detected = [fallacy for fallacy in fallacies if fallacy != \"no fallacy\"]\n",
        "\n",
        "print(\"Fallacies detected in the text:\")\n",
        "print(fallacies_detected)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iG7tpYpb5ooR",
        "outputId": "20d34f1e-0bc3-4086-9471-6135b8d6a533"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fallacies detected in the text:\n",
            "['After analyzing the text, I can confidently say that it does not contain the fallacy of \"slippery slope\".\\n\\nThe text is actually committing a different fallacy, specifically the \"appeal to anecdote\" or \"personal experience\". The author is using their father\\'s personal experience as evidence to support the claim that smoking is not bad for you, which is a weak and unreliable argument.\\n\\nThe text does not present a logical progression or a series of events that would lead to an unintended and undesirable consequence, which is the defining characteristic of the \"slippery slope\" fallacy.', 'A great example!\\n\\nAfter analyzing the text, I can confidently say that it contains the fallacy of \"hasty generalization\".\\n\\nThe text states that the author\\'s father smoked heavily and lived a long life, and therefore, the author concludes that smoking \"really can\\'t be that bad for you\". However, this conclusion is based on a single anecdote (the author\\'s father\\'s experience) and does not account for the vast majority of people who smoke and do not live as long as the author\\'s father.\\n\\nThe author is making a general claim (\"smoking really can\\'t be that bad for you\") based on a very limited sample size (one person, their father) and ignoring the vast amount of evidence that suggests smoking is harmful to one\\'s health. This is a classic example of a hasty generalization, where a conclusion is drawn from a small, unrepresentative sample, rather than considering the broader evidence.\\n\\nSo, my answer is: \"hasty generalization\"!', 'A great example!\\n\\nAfter analyzing the text, I can confidently say that it contains the fallacy of \"false analogy\".\\n\\nHere\\'s why:\\n\\nThe text compares the situation of the author\\'s father, who smoked heavily and lived a long life, to the general statement about smoking being bad for you. However, these two situations are vastly different.\\n\\nThe author\\'s father is an individual with a unique genetic makeup, health conditions, and lifestyle, which may have influenced his ability to smoke heavily and still live a long life. In contrast, the general statement about smoking being bad for you is a broad claim that applies to the population as a whole, considering the overwhelming scientific evidence and the known risks of smoking.\\n\\nBy drawing an analogy between these two situations, the author is committing a false analogy fallacy. The conclusion that \"smoking really can\\'t be that bad for you\" is not supported by the example of the author\\'s father, and it oversimplifies the complex relationship between smoking and health outcomes.\\n\\nTherefore, my answer is: \"false analogy\".', 'A great example!\\n\\nAfter analyzing the text, I can confidently say that it contains the fallacy of \"guilt by association\".\\n\\nHere\\'s why:\\n\\nThe author is trying to argue that smoking is not harmful by pointing out that their father, who smoked heavily, lived a long life. The author is associating their father\\'s smoking habit with his longevity, implying that if their father, who smoked heavily, lived to be 95, then smoking can\\'t be that bad for you. This is an attempt to discredit the negative effects of smoking by associating it with a positive outcome (their father\\'s longevity) without providing any actual evidence or logical reasoning to support their claim.\\n\\nThis is a classic example of guilt by association, where the author is trying to undermine the credibility of the negative effects of smoking by linking it to a positive outcome (their father\\'s longevity) without providing any logical connection between the two.\\n\\nSo, my answer is: \"guilt by association\"!', 'A great example!\\n\\nAfter analyzing the text, I can confirm that it indeed contains the fallacy of \"causal oversimplification\".\\n\\nThe text is making a simplistic and overly broad claim that because one person smoked heavily and lived a long life, smoking cannot be bad for you. This ignores many other factors that could have contributed to the person\\'s longevity, such as genetics, lifestyle choices, and access to healthcare. It also oversimplifies the complex relationship between smoking and health outcomes, implying that smoking is harmless simply because one person lived a long life despite smoking.\\n\\nTherefore, I return: \"causal oversimplification\"', 'A great example!\\n\\nAfter analyzing the text, I can confirm that it contains the fallacy of \"ad populum\" (appeal to popularity).\\n\\nHere\\'s why:\\n\\nThe text states that the author\\'s father smoked heavily for most of his life and lived until 95, implying that smoking can\\'t be that bad for you. The conclusion is based on the fact that the author\\'s father, an individual, lived a long life despite smoking heavily. This is an anecdotal example, and the author is using it to make a general statement about the effects of smoking on health.\\n\\nThe fallacy lies in the assumption that because one person, in this case, the author\\'s father, lived a long life despite smoking, it must be true for everyone. This ignores the vast amount of scientific evidence and data that suggest smoking is a significant risk factor for various health problems.\\n\\nIn this case, the text is committing the fallacy of \"ad populum\" by using the popularity of the author\\'s father\\'s longevity to support a conclusion that is not universally applicable.\\n\\nSo, my answer is: \"ad populum\"!', 'A great example!\\n\\nAfter analyzing the text, I can confidently say that it contains the fallacy of \"circular reasoning\".\\n\\nThe argument goes like this:\\n\\n\"My father smoked four packs of cigarettes a day from age 14 and lived until the age of 95. So smoking really can’t be that bad for you.\"\\n\\nThe fallacy lies in the fact that the conclusion (\"smoking really can’t be that bad for you\") relies on the same evidence that is being used to support the premise (\"My father smoked four packs of cigarettes a day from age 14 and lived until the age of 95\"). In other words, the conclusion is simply a reiteration of the premise, without providing any additional evidence or logical connection to support the claim.\\n\\nThis is a classic example of circular reasoning, where the argument is essentially saying \"My father smoked and lived a long life, therefore smoking is good for you\" – which is a tautology, as the conclusion is already assumed in the premise.\\n\\nSo, I return: \"circular reasoning\"', \"After analyzing the text, I did not find an appeal to fear fallacy. The text is making a claim based on the author's personal experience and observation, which is a form of anecdotal evidence. The author is simply stating that their father smoked heavily and lived a long life, and is concluding that smoking is not harmful. This is a flawed argument, as it relies on a single, anecdotal example and ignores the overwhelming scientific evidence that smoking is harmful to one's health.\\n\\nThe fallacy present in this text is actually an Appeal to Consequence, which is the fallacy of assuming that because something has a certain consequence, it must be true. In this case, the author is assuming that because their father lived a long life despite smoking heavily, it must mean that smoking is not harmful.\\n\\nSo, my answer is: no fallacy (appeal to fear), but rather an Appeal to Consequence.\", \"A great example!\\n\\nAfter analyzing the text, I have identified a fallacy: **False Causality**!\\n\\nThe text claims that since the person's father smoked heavily and lived a long life, smoking can't be that bad for you. However, this is a false conclusion. The text does not establish a causal relationship between smoking and longevity. The father's smoking habits might have been a contributing factor to his early death, not his longevity.\\n\\nIn this case, the text is committing the fallacy of false causality, as it is incorrectly concluding that smoking is beneficial because of the father's longevity, without considering other possible factors that might have contributed to his long life.\\n\\nSo, my answer is: **False Causality**!\", 'After analyzing the text, I conclude that it contains the fallacy of division.\\n\\nThe fallacy of division is committed when a general statement is applied to a specific case without considering the differences between the two. In this text, the author is making a general statement about smoking (\"smoking really can\\'t be that bad for you\") and applying it to a specific case (their father\\'s experience). However, the author ignores the fact that their father was an exceptional case, with a unique set of circumstances (smoking four packs a day from age 14, which is extremely rare and not representative of typical smoking habits).\\n\\nThe author is drawing a conclusion about the general effects of smoking on health based on a single, exceptional case. This is a classic example of the fallacy of division, as the author is ignoring the differences between the general case (smoking in general) and the specific case (their father\\'s smoking habits).\\n\\nTherefore, I return: \"fallacy of division\".', 'After analyzing the text, I found that it does not contain the fallacy of \"appeal to ridicule\".\\n\\nThe text presents a personal anecdote about the author\\'s father, who smoked heavily and lived a long life. The conclusion drawn is that smoking can\\'t be that bad for you. This is an example of an anecdotal argument, which can be flawed due to the limitations of a single case study.\\n\\nHowever, it does not involve ridiculing or mocking someone\\'s argument, which is the characteristic of the \"appeal to ridicule\" fallacy. Therefore, my answer is:\\n\\nno fallacy', 'A great example!\\n\\nAfter analyzing the text, I conclude that it indeed contains the fallacy of \"appeal to worse problems\".\\n\\nThe text attempts to argue that smoking can\\'t be that bad for you because someone\\'s father, who smoked heavily, lived a long life. The fallacy is that the argument is trying to deflect attention away from the issue of smoking\\'s potential harm by pointing to an even more serious problem (in this case, the fact that someone\\'s father lived to 95 despite smoking heavily). The implication is that since there\\'s a \"worse\" problem (e.g., children starving), we shouldn\\'t worry about the relatively \"better\" problem (e.g., the health risks of smoking).\\n\\nThe correct response should be: \"Return \\'appeal to worse problems\\'\".', 'A great example!\\n\\nAfter analyzing the text, I can conclude that it does contain the fallacy of \"abusive ad hominem\".\\n\\nThe original text is trying to dismiss the negative effects of smoking by pointing to the longevity of the author\\'s father, who smoked heavily. However, the author is not addressing the argument itself, but instead using a personal anecdote to attack the credibility of the opposing view. In this case, the author is implying that anyone who says smoking is bad is wrong because their own father, who smoked heavily, lived a long life.\\n\\nThis is an example of an abusive ad hominem, as the author is not engaging with the argument, but instead attacking the credibility of the opposing viewpoint by making a personal attack (in this case, by implying that the opposing view is held by someone who is \"wrong\" because of their father\\'s longevity).', 'A great example!\\n\\nAfter analyzing the text, I conclude that it contains the fallacy of \"appeal to false authority\".\\n\\nThe text appeals to the authority of the author\\'s father, who smoked heavily and lived a long life, to support the claim that smoking is not bad for you. However, this is a flawed argument because the father\\'s experience is anecdotal and does not provide conclusive evidence for the safety of smoking. Additionally, there are many other factors that could have contributed to the father\\'s longevity, unrelated to smoking.\\n\\nThe fallacy is that the author is using their father\\'s personal experience as a basis for a general claim, without considering the overwhelming scientific evidence that smoking is harmful to one\\'s health.', 'A great example!\\n\\nAfter analyzing the text, I can confidently say that it contains the fallacy of \"appeal to positive emotion\".\\n\\nThe text is trying to persuade by appealing to the positive emotion of admiration for the longevity of the person\\'s father, who smoked heavily but lived a long life. The argument is attempting to evoke a feeling of \"wow, if someone who smokes that much can live that long, it can\\'t be that bad for you\" rather than presenting a logical and evidence-based argument about the effects of smoking.\\n\\nThe fallacy is that the argument relies on the emotional response to the longevity of the person\\'s father, rather than presenting a valid and reliable conclusion about the safety of smoking.', 'A great example!\\n\\nAfter analyzing the text, I can confidently identify the fallacy as... \"Appeal to Nature\"!\\n\\nThe argument is: \"My father smoked four packs of cigarettes a day from age 14 and lived until the age of 95. So smoking really can’t be that bad for you.\"\\n\\nThe fallacy is that the speaker is using their father\\'s experience as a natural phenomenon to justify the conclusion that smoking is not harmful. They\\'re implying that since their father, a natural person, lived a long life despite smoking heavily, it must be natural and therefore acceptable. This is an example of an Appeal to Nature, as it relies on the idea that natural things are inherently good or beneficial, without considering the evidence or scientific consensus on the topic.\\n\\nWell done on providing a great example!', 'A great example!\\n\\nAfter analyzing the text, I found that it indeed contains the fallacy of equivocation.\\n\\nThe fallacy occurs when the word \"bad\" is used in two different ways. In the first part of the sentence, \"bad\" refers to the negative effects of smoking on one\\'s health. However, in the second part, \"bad\" is used to imply that smoking is not extremely harmful, as the person\\'s father lived to be 95 despite smoking heavily.\\n\\nThe equivocation occurs when the word \"bad\" is used to convey two different meanings, without a clear distinction being made between them. The speaker is using the fact that the father lived a long life despite smoking heavily to argue that smoking can\\'t be that bad, when in reality, the evidence only shows that smoking has some positive effects (e.g., the father lived a long life), but not that it\\'s harmless.\\n\\nTherefore, my answer is: \"equivocation\".', 'After analyzing the text, I conclude that it does not contain the fallacy of \"appeal to anger\".\\n\\nThe text presents a personal anecdote about the author\\'s father, who smoked heavily but lived a long life. The author then draws a conclusion that smoking \"really can\\'t be that bad\" based on this example. This is an example of a logical fallacy known as \"appeal to anecdote\" or \"personal experience\", where an argument is based on a single, unrepresentative example rather than evidence-based reasoning.\\n\\nHowever, it does not contain an appeal to anger, which would involve attempting to elicit an emotional response (such as anger) to influence the audience\\'s judgment or decision. In this case, the text is simply presenting a personal experience and drawing a conclusion based on that experience.\\n\\nTherefore, my answer is: \"no fallacy\".', 'A great example!\\n\\nAfter analyzing the text, I can confidently say that it contains the fallacy of... **false dilemma**!\\n\\nHere\\'s why:\\n\\nThe argument presents a simplistic and flawed dichotomy: \"smoking really can\\'t be that bad for you\" because the person\\'s father smoked heavily and lived to be 95. This implies that there are only two possibilities: either smoking is harmless, or it\\'s extremely harmful. This is a false dichotomy, as there are many other possible outcomes and nuances in between.\\n\\nThe argument ignores the possibility that the person\\'s father might have been an exception due to various factors, such as his overall health, lifestyle, or genetic predispositions. It also overlooks the fact that smoking is a significant risk factor for various health problems, and even if the person\\'s father lived to be 95, that doesn\\'t mean smoking didn\\'t have any negative effects on his health.\\n\\nSo, the answer is: **false dilemma**!', 'After analyzing the text, I can confidently say that it contains the fallacy of \"straw man\".\\n\\nThe original argument against smoking is likely that it\\'s a significant risk factor for various health problems and premature death. However, the text presents a distorted and exaggerated version of this argument, implying that opponents of smoking claim that it\\'s completely harmless. This is a straw man fallacy because it misrepresents the opposing view and creates a weak, easy-to-defeat argument.\\n\\nIn reality, opponents of smoking are unlikely to claim that smoking is completely harmless. Instead, they would argue that the risks associated with smoking outweigh any potential benefits, and that quitting or reducing smoking is a healthier choice.\\n\\nSo, the correct answer is: \"straw man\".', 'After analyzing the text, I can confirm that it indeed contains the fallacy of \"appeal to tradition\".\\n\\nThe text argues that since the person\\'s father smoked heavily and lived a long life, smoking must not be that bad for you. This is an appeal to tradition because it relies on the idea that because something has been done a certain way in the past (the father\\'s smoking habits), it must be acceptable or even beneficial. This ignores the possibility that there may be other factors at play, such as the father\\'s overall health, lifestyle, or genetic predispositions, that contributed to his longevity.\\n\\nTherefore, I return: \"appeal to tradition\".', 'A classic example!\\n\\nYes, I detect the fallacy of \"tu quoque\" (Latin for \"you too\") in the given text. The argument is:\\n\\n\"My father smoked four packs of cigarettes a day from age 14 and lived until the age of 95. So smoking really can’t be that bad for you.\"\\n\\nThe fallacy is that the speaker is trying to discredit the potential harm of smoking by pointing out that their father, who smoked excessively, lived a long life. This is an attempt to deflect the argument by saying, \"Hey, if it was bad for you, then it must be okay for me too, since my father, who did it, lived a long life.\" This is a logical fallacy, as the fact that someone\\'s father lived a long life despite smoking does not necessarily mean that smoking is not harmful.\\n\\nSo, the answer is: \"tu quoque\"!']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Improved prompt bith LLM generated examples."
      ],
      "metadata": {
        "id": "fDjp8GM_ISHl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the text to check for fallacies\n",
        "text_to_check = '''\n",
        "The teenagers where rude and disrespectful therefore all teenagers are rude and disrespectful.\n",
        "'''\n",
        "\n",
        "\n",
        "# Construct the user message for prompting\n",
        "user_message = [\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful assistant!\"},\n",
        "    {\"role\": \"user\", \"content\": f\"\"\"Please identify any and all logical fallacies present in the following text.\\n\n",
        "    Let's think step by step by going through every sentence and checking them for every single fallacy:\\n{text_to_check}\"\"\"}\n",
        "]\n",
        "\n",
        "# Generate the prompt with the examples of each fallacy\n",
        "prompt_messages = user_message + [\n",
        "    {\"role\": \"user\", \"content\": \"\"\"Identify if this text contains the fallacy 'slippery slope'. Here is an example for a slippery slope:\\n\n",
        "    If we ban assault rifles, next they'll ban all guns, and before you know it, we'll be living in a police state.\"\"\"},\n",
        "    {\"role\": \"user\", \"content\": \"\"\"Identify if this text contains the fallacy 'hasty generalization'. Here is an example for a hasty generalization:\\n\n",
        "    I met two people from New York City, and both were rude. Therefore, all New Yorkers are rude.\"\"\"},\n",
        "    {\"role\": \"user\", \"content\": \"\"\"Identify if this text contains the fallacy 'false analogy'. Here is an example for a false analogy:\\n\n",
        "    Comparing buying a car to choosing a spouse is a false analogy because the two situations are vastly different.\"\"\"},\n",
        "    {\"role\": \"user\", \"content\": \"\"\"Identify if this text contains the fallacy 'guilt by association'. Here is an example for guilt by association:\\n\n",
        "    You shouldn't listen to John's opinion on politics; he's friends with several criminals.\"\"\"},\n",
        "    {\"role\": \"user\", \"content\": \"\"\"Identify if this text contains the fallacy 'causal oversimplification'. Here is an example for causal oversimplification:\\n\n",
        "    The rise in crime rates is due to violent video games; therefore, banning them will solve the problem.\"\"\"},\n",
        "    {\"role\": \"user\", \"content\": \"\"\"Identify if this text contains the fallacy 'ad populum'. Here is an example for ad populum:\\n\n",
        "    Everyone is buying the new smartphone, so it must be the best one on the market.\"\"\"},\n",
        "    {\"role\": \"user\", \"content\": \"\"\"Identify if this text contains the fallacy 'circular reasoning'. Here is an example for circular reasoning:\\n\n",
        "    The Bible is the word of God because God says it is in the Bible.\"\"\"},\n",
        "    {\"role\": \"user\", \"content\": \"\"\"Identify if this text contains the fallacy 'appeal to fear'. Here is an example for appeal to fear:\\n\n",
        "    If you don't vote for me, your taxes will skyrocket and crime will run rampant.\"\"\"},\n",
        "    {\"role\": \"user\", \"content\": \"\"\"Identify if this text contains the fallacy 'false causality'. Here is an example for false causality:\\n\n",
        "    Every time I wash my car, it rains. Therefore, washing my car causes rain.\"\"\"},\n",
        "    {\"role\": \"user\", \"content\": \"\"\"Identify if this text contains the fallacy 'fallacy of division'. Here is an example for fallacy of division:\\n\n",
        "    That company is profitable, so all of its employees must be well-paid.\"\"\"},\n",
        "    {\"role\": \"user\", \"content\": \"\"\"Identify if this text contains the fallacy 'appeal to ridicule'. Here is an example for appeal to ridicule:\\n\n",
        "    You shouldn't listen to Mary's argument about climate change; she believes the Earth is flat.\"\"\"},\n",
        "    {\"role\": \"user\", \"content\": \"\"\"Identify if this text contains the fallacy 'appeal to worse problems'. Here is an example for appeal to worse problems:\\n\n",
        "    Why are we worrying about pollution when there are children starving in the world.\"\"\"},\n",
        "    {\"role\": \"user\", \"content\": \"\"\"Identify if this text contains the fallacy 'abusive ad hominem'. Here is an example for abusive ad hominem:\\n\n",
        "    You can't trust anything Tom says; he's just a loser.\"\"\"},\n",
        "    {\"role\": \"user\", \"content\": \"\"\"Identify if this text contains the fallacy 'appeal to false authority'. Here is an example for appeal to false authority:\\n\n",
        "    My doctor says that smoking is good for you, so it must be true.\"\"\"},\n",
        "    {\"role\": \"user\", \"content\": \"\"\"Identify if this text contains the fallacy 'appeal to positive emotion'. Here is an example for appeal to positive emotion:\\n\n",
        "    If you care about the environment, you'll buy this eco-friendly product.\"\"\"},\n",
        "    {\"role\": \"user\", \"content\": \"\"\"Identify if this text contains the fallacy 'appeal to nature'. Here is an example for appeal to nature:\\n\n",
        "    Natural remedies are always better than pharmaceutical drugs.\"\"\"},\n",
        "    {\"role\": \"user\", \"content\": \"\"\"Identify if this text contains the fallacy 'equivocation'. Here is an example for equivocation:\\n\n",
        "    The sign said 'Fine for parking here,' so I thought it would be fine to park there.\"\"\"},\n",
        "    {\"role\": \"user\", \"content\": \"\"\"Identify if this text contains the fallacy 'appeal to anger'. Here is an example for appeal to anger:\\n\n",
        "    You wouldn't want to be a coward, would you? Then you better join the military!\"\"\"},\n",
        "    {\"role\": \"user\", \"content\": \"\"\"Identify if this text contains the fallacy 'false dilemma'. Here is an example for false dilemma:\\n\n",
        "    Either we ban all guns or we'll continue to have mass shootings.\"\"\"},\n",
        "    {\"role\": \"user\", \"content\": \"\"\"Identify if this text contains the fallacy 'straw man'. Here is an example for straw man:\\n\n",
        "    Opponents of gun control argue that we should give guns to everyone, including criminals and children.\"\"\"},\n",
        "    {\"role\": \"user\", \"content\": \"\"\"Identify if this text contains the fallacy 'appeal to tradition'. Here is an example for appeal to tradition:\\n\n",
        "    We should continue to use fossil fuels because that's how we've always done it.\"\"\"},\n",
        "    {\"role\": \"user\", \"content\": \"\"\"Identify if this text contains the fallacy 'tu quoque'. Here is an example for tu quoque:\\n\n",
        "    You say I shouldn't smoke, but I've seen you smoke before!\"\"\"},\n",
        "    {\"role\": \"user\", \"content\": \"\"\"Please return your answer only in this format, \\n\n",
        "    where in each item you return the content of the sentences where you find a fallacy in\\n\n",
        "    and then the fallacy class and nothing else. There can be one, many or no fallacies (no fallacies = []) in the text. This is the pattern: \\n\n",
        "    [{\"text\": “sentence1”, \"class\": \"\"}, {\"text\": \"sentence1\", \"class\": \"\"}, {\"text\": \"sentence3\", \"class\": \"\"}]\"\"\"}\n",
        "]\n",
        "\n",
        "prompt = pipeline.tokenizer.apply_chat_template(\n",
        "        prompt_messages,\n",
        "        tokenize=False,\n",
        "        add_generation_prompt=True\n",
        ")\n",
        "\n",
        "terminators = [\n",
        "    pipeline.tokenizer.eos_token_id,\n",
        "    pipeline.tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
        "]\n",
        "\n",
        "outputs = pipeline(\n",
        "    prompt,\n",
        "    max_new_tokens=512,\n",
        "    eos_token_id=terminators,\n",
        "    do_sample=True,\n",
        "    temperature=0.6,\n",
        "    top_p=0.9,\n",
        ")\n",
        "\n",
        "print(outputs[0][\"generated_text\"][len(prompt):])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fDsY8RmD7FBh",
        "outputId": "f8eb8335-10ef-4597-9217-59fee2f84040"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{\"text\": \"The teenagers where rude and disrespectful therefore all teenagers are rude and disrespectful.\", \"class\": \"hasty generalization\"}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Improved prompt with examples from literature"
      ],
      "metadata": {
        "id": "5Z1Nk4qJIa_b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the text to check for fallacies\n",
        "text_to_check = '''\n",
        "TITLE: So Pointy! POST: I dont have to justify it, vegans assume most people consider an animal life to be on par with human life, its not. If I was in the position to save my pet or a stranger Id never met before of course I would save the human. I dont want animals to suffer and I earn enough that I can afford to buy free range meat from reliable sources, I dont feel bad that an animal was killed so I can eat it, I dont believe its wrong in anyway so long as while its alive it isnt mistreated. There is nothing morally wrong about killing animals for food, you realise animals kill other animals for food too right?\n",
        "'''\n",
        "\n",
        "\n",
        "# Construct the user message for prompting\n",
        "user_message = [\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful assistant which is an expert in detecting logical fallacies!\"},\n",
        "    {\"role\": \"user\", \"content\": f\"\"\"Please identify any and all logical fallacies present in the following text.\\n\n",
        "    Let's think step by step by going through every sentence and checking them for every single fallacy:\\n{text_to_check}\"\"\"}\n",
        "]\n",
        "\n",
        "# Generate the prompt with the examples of each fallacy\n",
        "prompt_messages = user_message + [\n",
        "    {\"role\": \"user\", \"content\": \"\"\"Identify if this text contains the fallacy 'slippery slope'. Here is an example for a slippery slope: Person A: “I think we should lower the legal drinking age.” Person B: “No, if we do that, we’ll have ten-year-olds getting drunk in bars!”\"\"\"},\n",
        "    {\"role\": \"user\", \"content\": \"\"\"Identify if this text contains the fallacy 'hasty generalization'. Here is an example for a hasty generalization: You have a transit flight via Frankfurt Airport, Germany. On the way to your gate, several passengers hastily bump into you without even apologizing. You conclude that “Germans are so rude!”\"\"\"},\n",
        "    {\"role\": \"user\", \"content\": \"\"\"Identify if this text contains the fallacy 'false analogy'. Here is an example for a false analogy: Love is like a spring shower. It brings refreshment to a person's body. (Does it also sometimes lead to thunderstorms and being hit by lightning?)\"\"\"},\n",
        "    {\"role\": \"user\", \"content\": \"\"\"Identify if this text contains the fallacy 'guilt by association'. Here is an example for guilt by association: This form of the argument is as follows: Group A makes a particular claim. Group B, which is currently viewed negatively by some, makes the same claim as Group A. Therefore, Group A is viewed as associated with Group B, and is now also viewed negatively. An example of this fallacy would be \"My opponent for office just received an endorsement from the Puppy Haters Association. Is that the sort of person you would want to vote for?\"\"\"},\n",
        "    {\"role\": \"user\", \"content\": \"\"\"Identify if this text contains the fallacy 'causal oversimplification'. Here is an example for causal oversimplification: 'I water the garden every day, which is why it grows so well.' Watering the garden is certainly one cause of its growth, but the soil quality, amount of sunlight, and number of pests in the area are also major causes.\"\"\"},\n",
        "    {\"role\": \"user\", \"content\": \"\"\"Identify if this text contains the fallacy 'ad populum'. Here is an example for ad populum: You’re at a bookstore browsing for books with a friend. Although you are an avid sci-fi reader, your friend picks up a memoir and tells you that you should read the book because it’s a bestseller.\"\"\"},\n",
        "    {\"role\": \"user\", \"content\": \"\"\"Identify if this text contains the fallacy 'circular reasoning'. Here is an example for circular reasoning: Parent: “It’s time to go to bed.” Child: “Why?” Parent: “Because this is your bedtime.”\"\"\"},\n",
        "    {\"role\": \"user\", \"content\": \"\"\"Identify if this text contains the fallacy 'appeal to fear'. Here is an example for appeal to fear: Either P or Q is true. Q is frightening. Therefore, P is true.\"\"\"},\n",
        "    {\"role\": \"user\", \"content\": \"\"\"Identify if this text contains the fallacy 'false causality'. Here is an example for false causality: Every time I bring my umbrella with me, it rains. Clearly, if I leave it at home, there will be sunshine!\"\"\"},\n",
        "    {\"role\": \"user\", \"content\": \"\"\"Identify if this text contains the fallacy 'fallacy of division'. Here is an example for fallacy of division: The second grade in Jefferson Elementary eats a lot of ice cream Carlos is a second-grader in Jefferson Elementary Therefore, Carlos eats a lot of ice cream\"\"\"},\n",
        "    {\"role\": \"user\", \"content\": \"\"\"Identify if this text contains the fallacy 'appeal to ridicule'. Here is an example for appeal to ridicule: Person A: At one time in prehistory, the continents were fused together into a single supercontinent, which we call Pangaea. Person B: Yes, I definitely believe that hundreds of millions of years ago, some laser cut through the Earth and broke apart a giant landmass into many different pieces.\"\"\"},\n",
        "    {\"role\": \"user\", \"content\": \"\"\"Identify if this text contains the fallacy 'appeal to worse problems'. Here is an example for appeal to worse problems: Everyone should wear seatbelts. We should also wear bibs and sleep in a bassinet.\"\"\"},\n",
        "    {\"role\": \"user\", \"content\": \"\"\"Identify if this text contains the fallacy 'abusive ad hominem'. Here is an example for abusive ad hominem: who is going to vote for a person looking like this?\"\"\"},\n",
        "    {\"role\": \"user\", \"content\": \"\"\"Identify if this text contains the fallacy 'appeal to false authority'. Here is an example for appeal to false authority: My favorite actor, who starred in that movie about a virus that turns people into zombies, said in an interview that genetically modified crops caused COVID-19. So I think that’s what really happened\"\"\"},\n",
        "    {\"role\": \"user\", \"content\": \"\"\"Identify if this text contains the fallacy 'appeal to positive emotion'. Here is an example for appeal to positive emotion: Your sibling is trying to convince you to let them eat the last piece of the dessert: “Can I have the last piece of cake? You know how much I love it, and it's been a tough day for me. I've had such a bad day, and this cake would just make me feel so much better.\"\"\"},\n",
        "    {\"role\": \"user\", \"content\": \"\"\"Identify if this text contains the fallacy 'appeal to nature'. Here is an example for appeal to nature: Herbal medicine is natural, so it's good for you.\"\"\"},\n",
        "    {\"role\": \"user\", \"content\": \"\"\"Identify if this text contains the fallacy 'equivocation'. Here is an example for equivocation: Premise 1: Annoying co-workers are a headache. Premise 2: Painkillers can help you get rid of a headache. Conclusion: Painkillers can help you get rid of annoying co-workers.\"\"\"},\n",
        "    {\"role\": \"user\", \"content\": \"\"\"Identify if this text contains the fallacy 'appeal to anger'. Here is an example for appeal to anger: Are you tired of being ignored by your government?  Is it right that the top 1% have so much when the rest of us have so little?  I urge you to vote for me today!\"\"\"},\n",
        "    {\"role\": \"user\", \"content\": \"\"\"Identify if this text contains the fallacy 'false dilemma'. Here is an example for false dilemma: Either you support this new legislation to give the police more power, or you want society to descend into chaos!\"\"\"},\n",
        "    {\"role\": \"user\", \"content\": \"\"\"Identify if this text contains the fallacy 'straw man'. Here is an example for straw man: Person 1: I think we should increase benefits for unemployed single mothers during the first year after childbirth because they need sufficient money to provide medical care for their children. Person 2: So you believe we should give incentives to women to become single mothers and get a free ride from the tax money of hard-working citizens. This is just going to hurt our economy and our society in the long run.\"\"\"},\n",
        "    {\"role\": \"user\", \"content\": \"\"\"Identify if this text contains the fallacy 'appeal to tradition'. Here is an example for appeal to tradition: This medicine has been used by people since ancient history, therefore it must be an effective way to treat diseases.\"\"\"},\n",
        "    {\"role\": \"user\", \"content\": \"\"\"Identify if this text contains the fallacy 'tu quoque'. Here is an example for tu quoque: You used to do that when you were my age.\"\"\"},\n",
        "    {\"role\": \"user\", \"content\": \"\"\"Please return your answer only in this format, where in each item you return the content of the sentences where you find a fallacy in and then the fallacy class and nothing else. There can be one, many or no fallacies (no fallacies = []) in the text. This is the pattern: [{\"text\": “sentence1”, \"class\": \"\"}, {\"text\": \"sentence1\", \"class\": \"\"}, {\"text\": \"sentence3\", \"class\": \"\"}]\"\"\"}\n",
        "]\n",
        "\n",
        "prompt = pipeline.tokenizer.apply_chat_template(\n",
        "        prompt_messages,\n",
        "        tokenize=False,\n",
        "        add_generation_prompt=True\n",
        ")\n",
        "\n",
        "terminators = [\n",
        "    pipeline.tokenizer.eos_token_id,\n",
        "    pipeline.tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
        "]\n",
        "\n",
        "outputs = pipeline(\n",
        "    prompt,\n",
        "    max_new_tokens=512,\n",
        "    eos_token_id=terminators,\n",
        "    do_sample=True,\n",
        "    temperature=0.6,\n",
        "    top_p=0.9,\n",
        ")\n",
        "\n",
        "print(outputs[0][\"generated_text\"][len(prompt):])"
      ],
      "metadata": {
        "id": "IKnOEL5kC38D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "683ccf59-929b-4372-f121-f3bfef6f7946"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{\"text\": \"I dont want animals to suffer and I earn enough that I can afford to buy free range meat from reliable sources, I dont feel bad that an animal was killed so I can eat it, I dont believe its wrong in anyway so long as while its alive it isnt mistreated.\", \"class\": \"appeal to emotion\"}]\n",
            "\n",
            "Note: The text contains an appeal to emotion, specifically an appeal to the reader's emotions by stating that the writer doesn't feel bad about killing animals for food as long as it's done humanely.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Singular prompt:"
      ],
      "metadata": {
        "id": "VrWA7uiRzPqn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the text to check for fallacies\n",
        "text_to_check = '''\n",
        "TITLE: What would people think about preventing people from switching out from a pilot seat? i.e. to a gunner position; you'd still be able to bail. POST: This is a ridiculous post and this mechanic will never be changed. Seat switching has always been a BF mechanic. Dont sit here and try and talk about realism or how you shouldnt be able to swap instantly between seats when there is hardly anything realistic about BF vehicle play in general. Sounds like you need to get better if you are having trouble shooting down the most vulnerable aircraft in the sky.\n",
        "'''\n",
        "\n",
        "\n",
        "# Construct the user message for prompting\n",
        "user_message = [\n",
        "    {\"role\": \"system\", \"content\": f\"\"\"You are a helpful assistant which is an expert in detecting logical fallacies!\n",
        "    Please identify any and all logical fallacies present in the following text.\\n\n",
        "    Let's think step by step by going through the sentences and checking them for every single fallacy:\\n{text_to_check}\"\"\"}\n",
        "]\n",
        "\n",
        "# Generate the prompt with the examples of each fallacy\n",
        "prompt_messages = user_message + [\n",
        "    {\"role\": \"user\", \"content\": \"\"\"Identify if this text contains the fallacy 'slippery slope'. Here is an example for a slippery slope: Person A: “I think we should lower the legal drinking age.” Person B: “No, if we do that, we’ll have ten-year-olds getting drunk in bars!”\n",
        "Identify if this text contains the fallacy 'hasty generalization'. Here is an example for a hasty generalization: You have a transit flight via Frankfurt Airport, Germany. On the way to your gate, several passengers hastily bump into you without even apologizing. You conclude that “Germans are so rude!”\n",
        "Identify if this text contains the fallacy 'false analogy'. Here is an example for a false analogy: Love is like a spring shower. It brings refreshment to a person's body. (Does it also sometimes lead to thunderstorms and being hit by lightning?)\n",
        "Identify if this text contains the fallacy 'guilt by association'. Here is an example for guilt by association: This form of the argument is as follows: Group A makes a particular claim. Group B, which is currently viewed negatively by some, makes the same claim as Group A. Therefore, Group A is viewed as associated with Group B, and is now also viewed negatively. An example of this fallacy would be \"My opponent for office just received an endorsement from the Puppy Haters Association. Is that the sort of person you would want to vote for?\"\n",
        "Identify if this text contains the fallacy 'causal oversimplification'. Here is an example for causal oversimplification: 'I water the garden every day, which is why it grows so well.' Watering the garden is certainly one cause of its growth, but the soil quality, amount of sunlight, and number of pests in the area are also major causes.\n",
        "Identify if this text contains the fallacy 'ad populum'. Here is an example for ad populum: You’re at a bookstore browsing for books with a friend. Although you are an avid sci-fi reader, your friend picks up a memoir and tells you that you should read the book because it’s a bestseller.\n",
        "Identify if this text contains the fallacy 'circular reasoning'. Here is an example for circular reasoning: Parent: “It’s time to go to bed.” Child: “Why?” Parent: “Because this is your bedtime.”\n",
        "Identify if this text contains the fallacy 'appeal to fear'. Here is an example for appeal to fear: Either P or Q is true. Q is frightening. Therefore, P is true.\n",
        "Identify if this text contains the fallacy 'false causality'. Here is an example for false causality: Every time I bring my umbrella with me, it rains. Clearly, if I leave it at home, there will be sunshine!\n",
        "Identify if this text contains the fallacy 'fallacy of division'. Here is an example for fallacy of division: The second grade in Jefferson Elementary eats a lot of ice cream Carlos is a second-grader in Jefferson Elementary Therefore, Carlos eats a lot of ice cream\n",
        "Identify if this text contains the fallacy 'appeal to ridicule'. Here is an example for appeal to ridicule: Person A: At one time in prehistory, the continents were fused together into a single supercontinent, which we call Pangaea. Person B: Yes, I definitely believe that hundreds of millions of years ago, some laser cut through the Earth and broke apart a giant landmass into many different pieces.\n",
        "Identify if this text contains the fallacy 'appeal to worse problems'. Here is an example for appeal to worse problems: Everyone should wear seatbelts. We should also wear bibs and sleep in a bassinet.\n",
        "Identify if this text contains the fallacy 'abusive ad hominem'. Here is an example for abusive ad hominem: who is going to vote for a person looking like this?\n",
        "Identify if this text contains the fallacy 'appeal to false authority'. Here is an example for appeal to false authority: My favorite actor, who starred in that movie about a virus that turns people into zombies, said in an interview that genetically modified crops caused COVID-19. So I think that’s what really happened\n",
        "Identify if this text contains the fallacy 'appeal to positive emotion'. Here is an example for appeal to positive emotion: Your sibling is trying to convince you to let them eat the last piece of the dessert: “Can I have the last piece of cake? You know how much I love it, and it's been a tough day for me. I've had such a bad day, and this cake would just make me feel so much better.”\n",
        "Identify if this text contains the fallacy 'appeal to nature'. Here is an example for appeal to nature: Herbal medicine is natural, so it's good for you.\n",
        "Identify if this text contains the fallacy 'equivocation'. Here is an example for equivocation: Premise 1: Annoying co-workers are a headache. Premise 2: Painkillers can help you get rid of a headache. Conclusion: Painkillers can help you get rid of annoying co-workers.\n",
        "Identify if this text contains the fallacy 'appeal to anger'. Here is an example for appeal to anger: Are you tired of being ignored by your government?  Is it right that the top 1% have so much when the rest of us have so little?  I urge you to vote for me today!\n",
        "Identify if this text contains the fallacy 'false dilemma'. Here is an example for false dilemma: Either you support this new legislation to give the police more power, or you want society to descend into chaos!\n",
        "Identify if this text contains the fallacy 'straw man'. Here is an example for straw man: Person 1: I think we should increase benefits for unemployed single mothers during the first year after childbirth because they need sufficient money to provide medical care for their children. Person 2: So you believe we should give incentives to women to become single mothers and get a free ride from the tax money of hard-working citizens. This is just going to hurt our economy and our society in the long run.\n",
        "Identify if this text contains the fallacy 'appeal to tradition'. Here is an example for appeal to tradition: This medicine has been used by people since ancient history, therefore it must be an effective way to treat diseases.\n",
        "Identify if this text contains the fallacy 'appeal to pity'. Here is an example for appeal to tradition: You must have graded my exam incorrectly. I studied very hard for weeks specifically because I knew my career depended on getting a good grade. If you give me a failing grade I'm ruined!\n",
        "Identify if this text contains the fallacy 'tu quoque'. Here is an example for tu quoque: You used to do that when you were my age\n",
        "Please return your answer only in this exact format with all the fallacies, where in each item for each fallacy you find, you return the content of a passage (can be multiple sentences long) where you find a fallacy, and then the fallacy class, and nothing else. If there are no fallacies, empty square brackets are returned: []. Passages can overlap and the same passage can contain multiple fallacies. Please make sure you find all the fallacies, not to miss any and not come up with false ones.\n",
        "    Format your answer to be only a singular list of all fallacies like this: [{\"text\": \"passage1\", \"class\": \"\"}, {\"text\": \"passage2\", \"class\": \"\"}, {\"text\": \"passage3\", \"class\": \"\"}].\"\"\"}\n",
        "]\n",
        "\n",
        "prompt = pipeline.tokenizer.apply_chat_template(\n",
        "        prompt_messages,\n",
        "        tokenize=False,\n",
        "        add_generation_prompt=True\n",
        ")\n",
        "\n",
        "terminators = [\n",
        "    pipeline.tokenizer.eos_token_id,\n",
        "    pipeline.tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
        "]\n",
        "\n",
        "outputs = pipeline(\n",
        "    prompt,\n",
        "    max_new_tokens=512,\n",
        "    eos_token_id=terminators,\n",
        "    do_sample=True,\n",
        "    temperature=0.6,\n",
        "    top_p=0.9,\n",
        ")\n",
        "\n",
        "print(outputs[0][\"generated_text\"][len(prompt):])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-zqtGXhyzLFk",
        "outputId": "3835c671-6ab7-4fff-8f03-d8aa232c756c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{\"text\": \"Dont sit here and try and talk about realism or how you shouldnt be able to swap instantly between seats when there is hardly anything realistic about BF vehicle play in general.\", \"class\": \"appeal to ridicule\"}]\n",
            "\n",
            "[{\"text\": \"Sounds like you need to get better if you are having trouble shooting down the most vulnerable aircraft in the sky.\", \"class\": \"abusive ad hominem\"}]\n",
            "\n",
            "[{\"text\": \"This is a ridiculous post and this mechanic will never be changed.\", \"class\": \"appeal to authority\"}]\n",
            "\n",
            "Note: The text does not contain the other fallacies mentioned.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Seperated prompt:"
      ],
      "metadata": {
        "id": "SM8yzsxhzLwQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the text to check for fallacies\n",
        "text_to_check = '''\n",
        "TITLE: What would people think about preventing people from switching out from a pilot seat? i.e. to a gunner position; you'd still be able to bail. POST: This is a ridiculous post and this mechanic will never be changed. Seat switching has always been a BF mechanic. Dont sit here and try and talk about realism or how you shouldnt be able to swap instantly between seats when there is hardly anything realistic about BF vehicle play in general. Sounds like you need to get better if you are having trouble shooting down the most vulnerable aircraft in the sky.\n",
        "'''\n",
        "\n",
        "\n",
        "# Construct the user message for prompting\n",
        "user_message = [\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful assistant which is an expert in detecting logical fallacies!\"},\n",
        "    {\"role\": \"user\", \"content\": f\"\"\"Please identify any and all logical fallacies present in the following text.\\n\n",
        "    Let's think step by step by going through the sentences and checking them for every single fallacy:\\n{text_to_check}\"\"\"}\n",
        "]\n",
        "\n",
        "# Generate the prompt with the examples of each fallacy\n",
        "prompt_messages = user_message + [\n",
        "    {\"role\": \"user\", \"content\": \"\"\"Identify if this text contains the fallacy 'slippery slope'. Here is an example for a slippery slope: Person A: “I think we should lower the legal drinking age.” Person B: “No, if we do that, we’ll have ten-year-olds getting drunk in bars!”\n",
        "Identify if this text contains the fallacy 'hasty generalization'. Here is an example for a hasty generalization: You have a transit flight via Frankfurt Airport, Germany. On the way to your gate, several passengers hastily bump into you without even apologizing. You conclude that “Germans are so rude!”\n",
        "Identify if this text contains the fallacy 'false analogy'. Here is an example for a false analogy: Love is like a spring shower. It brings refreshment to a person's body. (Does it also sometimes lead to thunderstorms and being hit by lightning?)\n",
        "Identify if this text contains the fallacy 'guilt by association'. Here is an example for guilt by association: This form of the argument is as follows: Group A makes a particular claim. Group B, which is currently viewed negatively by some, makes the same claim as Group A. Therefore, Group A is viewed as associated with Group B, and is now also viewed negatively. An example of this fallacy would be \"My opponent for office just received an endorsement from the Puppy Haters Association. Is that the sort of person you would want to vote for?\"\n",
        "Identify if this text contains the fallacy 'causal oversimplification'. Here is an example for causal oversimplification: 'I water the garden every day, which is why it grows so well.' Watering the garden is certainly one cause of its growth, but the soil quality, amount of sunlight, and number of pests in the area are also major causes.\n",
        "Identify if this text contains the fallacy 'ad populum'. Here is an example for ad populum: You’re at a bookstore browsing for books with a friend. Although you are an avid sci-fi reader, your friend picks up a memoir and tells you that you should read the book because it’s a bestseller.\n",
        "Identify if this text contains the fallacy 'circular reasoning'. Here is an example for circular reasoning: Parent: “It’s time to go to bed.” Child: “Why?” Parent: “Because this is your bedtime.”\n",
        "Identify if this text contains the fallacy 'appeal to fear'. Here is an example for appeal to fear: Either P or Q is true. Q is frightening. Therefore, P is true.\n",
        "Identify if this text contains the fallacy 'false causality'. Here is an example for false causality: Every time I bring my umbrella with me, it rains. Clearly, if I leave it at home, there will be sunshine!\n",
        "Identify if this text contains the fallacy 'fallacy of division'. Here is an example for fallacy of division: The second grade in Jefferson Elementary eats a lot of ice cream Carlos is a second-grader in Jefferson Elementary Therefore, Carlos eats a lot of ice cream\n",
        "Identify if this text contains the fallacy 'appeal to ridicule'. Here is an example for appeal to ridicule: Person A: At one time in prehistory, the continents were fused together into a single supercontinent, which we call Pangaea. Person B: Yes, I definitely believe that hundreds of millions of years ago, some laser cut through the Earth and broke apart a giant landmass into many different pieces.\n",
        "Identify if this text contains the fallacy 'appeal to worse problems'. Here is an example for appeal to worse problems: Everyone should wear seatbelts. We should also wear bibs and sleep in a bassinet.\n",
        "Identify if this text contains the fallacy 'abusive ad hominem'. Here is an example for abusive ad hominem: who is going to vote for a person looking like this?\n",
        "Identify if this text contains the fallacy 'appeal to false authority'. Here is an example for appeal to false authority: My favorite actor, who starred in that movie about a virus that turns people into zombies, said in an interview that genetically modified crops caused COVID-19. So I think that’s what really happened\n",
        "Identify if this text contains the fallacy 'appeal to positive emotion'. Here is an example for appeal to positive emotion: Your sibling is trying to convince you to let them eat the last piece of the dessert: “Can I have the last piece of cake? You know how much I love it, and it's been a tough day for me. I've had such a bad day, and this cake would just make me feel so much better.”\n",
        "Identify if this text contains the fallacy 'appeal to nature'. Here is an example for appeal to nature: Herbal medicine is natural, so it's good for you.\n",
        "Identify if this text contains the fallacy 'equivocation'. Here is an example for equivocation: Premise 1: Annoying co-workers are a headache. Premise 2: Painkillers can help you get rid of a headache. Conclusion: Painkillers can help you get rid of annoying co-workers.\n",
        "Identify if this text contains the fallacy 'appeal to anger'. Here is an example for appeal to anger: Are you tired of being ignored by your government?  Is it right that the top 1% have so much when the rest of us have so little?  I urge you to vote for me today!\n",
        "Identify if this text contains the fallacy 'false dilemma'. Here is an example for false dilemma: Either you support this new legislation to give the police more power, or you want society to descend into chaos!\n",
        "Identify if this text contains the fallacy 'straw man'. Here is an example for straw man: Person 1: I think we should increase benefits for unemployed single mothers during the first year after childbirth because they need sufficient money to provide medical care for their children. Person 2: So you believe we should give incentives to women to become single mothers and get a free ride from the tax money of hard-working citizens. This is just going to hurt our economy and our society in the long run.\n",
        "Identify if this text contains the fallacy 'appeal to tradition'. Here is an example for appeal to tradition: This medicine has been used by people since ancient history, therefore it must be an effective way to treat diseases.\n",
        "Identify if this text contains the fallacy 'appeal to pity'. Here is an example for appeal to tradition: You must have graded my exam incorrectly. I studied very hard for weeks specifically because I knew my career depended on getting a good grade. If you give me a failing grade I'm ruined!\n",
        "Identify if this text contains the fallacy 'tu quoque'. Here is an example for tu quoque: You used to do that when you were my age.\"\"\"},\n",
        "    {\"role\": \"user\", \"content\": \"\"\"Please return your answer only in this exact format with all the fallacies, where in each item for each fallacy you find, you return the content of a passage (can be multiple sentences long) where you find a fallacy, and then the fallacy class, and nothing else. If there are no fallacies, empty square brackets are returned: []. Passages can overlap and the same passage can contain multiple fallacies. Please make sure you find all the fallacies, not to miss any and not come up with false ones. \\n\n",
        "    This is the pattern I want your answer to be a list in square brackets: [{\"text\": \"passage1\", \"class\": \"\"}, {\"text\": \"passage2\", \"class\": \"\"}, {\"text\": \"passage3\", \"class\": \"\"}].\"\"\"}\n",
        "]\n",
        "\n",
        "prompt = pipeline.tokenizer.apply_chat_template(\n",
        "        prompt_messages,\n",
        "        tokenize=False,\n",
        "        add_generation_prompt=True\n",
        ")\n",
        "\n",
        "terminators = [\n",
        "    pipeline.tokenizer.eos_token_id,\n",
        "    pipeline.tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
        "]\n",
        "\n",
        "outputs = pipeline(\n",
        "    prompt,\n",
        "    max_new_tokens=512,\n",
        "    eos_token_id=terminators,\n",
        "    do_sample=True,\n",
        "    temperature=0.6,\n",
        "    top_p=0.9,\n",
        ")\n",
        "\n",
        "print(outputs[0][\"generated_text\"][len(prompt):])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SNCVysf3P9He",
        "outputId": "54464b6a-52ed-4982-99e3-81fa0b32061b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\n",
            "{\"text\": \"Dont sit here and try and talk about realism or how you shouldnt be able to swap instantly between seats when there is hardly anything realistic about BF vehicle play in general.\", \"class\": \"appeal to ridicule\"},\n",
            "{\"text\": \"Sounds like you need to get better if you are having trouble shooting down the most vulnerable aircraft in the sky.\", \"class\": \"abusive ad hominem\"}\n",
            "]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the text to check for fallacies\n",
        "text_to_check = '''\n",
        "TITLE: What would people think about preventing people from switching out from a pilot seat? i.e. to a gunner position; you'd still be able to bail. POST: This is a ridiculous post and this mechanic will never be changed. Seat switching has always been a BF mechanic. Dont sit here and try and talk about realism or how you shouldnt be able to swap instantly between seats when there is hardly anything realistic about BF vehicle play in general. Sounds like you need to get better if you are having trouble shooting down the most vulnerable aircraft in the sky.\n",
        "'''\n",
        "\n",
        "\n",
        "# Construct the user message for prompting\n",
        "user_message = [\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful assistant which is an expert in detecting logical fallacies!\"},\n",
        "    {\"role\": \"user\", \"content\": f\"\"\"Please go through the text and identify whether there is a logical fallacy in the following text, and if so, classify the text as the most appropriate logical fallacy:\n",
        "    {text_to_check}\"\"\"}\n",
        "]\n",
        "\n",
        "# Generate the prompt with the examples of each fallacy\n",
        "prompt_messages = user_message + [\n",
        "    {\"role\": \"user\", \"content\": \"\"\"Identify if this text contains the fallacy 'slippery slope'. Here is an example for a slippery slope: Person A: “I think we should lower the legal drinking age.” Person B: “No, if we do that, we’ll have ten-year-olds getting drunk in bars!”\n",
        "Identify if this text contains the fallacy 'hasty generalization'. Here is an example for a hasty generalization: You have a transit flight via Frankfurt Airport, Germany. On the way to your gate, several passengers hastily bump into you without even apologizing. You conclude that “Germans are so rude!”\n",
        "Identify if this text contains the fallacy 'false analogy'. Here is an example for a false analogy: Love is like a spring shower. It brings refreshment to a person's body. (Does it also sometimes lead to thunderstorms and being hit by lightning?)\n",
        "Identify if this text contains the fallacy 'guilt by association'. Here is an example for guilt by association: This form of the argument is as follows: Group A makes a particular claim. Group B, which is currently viewed negatively by some, makes the same claim as Group A. Therefore, Group A is viewed as associated with Group B, and is now also viewed negatively. An example of this fallacy would be \"My opponent for office just received an endorsement from the Puppy Haters Association. Is that the sort of person you would want to vote for?\"\n",
        "Identify if this text contains the fallacy 'causal oversimplification'. Here is an example for causal oversimplification: 'I water the garden every day, which is why it grows so well.' Watering the garden is certainly one cause of its growth, but the soil quality, amount of sunlight, and number of pests in the area are also major causes.\n",
        "Identify if this text contains the fallacy 'ad populum'. Here is an example for ad populum: You’re at a bookstore browsing for books with a friend. Although you are an avid sci-fi reader, your friend picks up a memoir and tells you that you should read the book because it’s a bestseller.\n",
        "Identify if this text contains the fallacy 'circular reasoning'. Here is an example for circular reasoning: Parent: “It’s time to go to bed.” Child: “Why?” Parent: “Because this is your bedtime.”\n",
        "Identify if this text contains the fallacy 'appeal to fear'. Here is an example for appeal to fear: Either P or Q is true. Q is frightening. Therefore, P is true.\n",
        "Identify if this text contains the fallacy 'false causality'. Here is an example for false causality: Every time I bring my umbrella with me, it rains. Clearly, if I leave it at home, there will be sunshine!\n",
        "Identify if this text contains the fallacy 'fallacy of division'. Here is an example for fallacy of division: The second grade in Jefferson Elementary eats a lot of ice cream Carlos is a second-grader in Jefferson Elementary Therefore, Carlos eats a lot of ice cream\n",
        "Identify if this text contains the fallacy 'appeal to ridicule'. Here is an example for appeal to ridicule: Person A: At one time in prehistory, the continents were fused together into a single supercontinent, which we call Pangaea. Person B: Yes, I definitely believe that hundreds of millions of years ago, some laser cut through the Earth and broke apart a giant landmass into many different pieces.\n",
        "Identify if this text contains the fallacy 'appeal to worse problems'. Here is an example for appeal to worse problems: Everyone should wear seatbelts. We should also wear bibs and sleep in a bassinet.\n",
        "Identify if this text contains the fallacy 'abusive ad hominem'. Here is an example for abusive ad hominem: who is going to vote for a person looking like this?\n",
        "Identify if this text contains the fallacy 'appeal to false authority'. Here is an example for appeal to false authority: My favorite actor, who starred in that movie about a virus that turns people into zombies, said in an interview that genetically modified crops caused COVID-19. So I think that’s what really happened\n",
        "Identify if this text contains the fallacy 'appeal to positive emotion'. Here is an example for appeal to positive emotion: Your sibling is trying to convince you to let them eat the last piece of the dessert: “Can I have the last piece of cake? You know how much I love it, and it's been a tough day for me. I've had such a bad day, and this cake would just make me feel so much better.”\n",
        "Identify if this text contains the fallacy 'appeal to nature'. Here is an example for appeal to nature: Herbal medicine is natural, so it's good for you.\n",
        "Identify if this text contains the fallacy 'equivocation'. Here is an example for equivocation: Premise 1: Annoying co-workers are a headache. Premise 2: Painkillers can help you get rid of a headache. Conclusion: Painkillers can help you get rid of annoying co-workers.\n",
        "Identify if this text contains the fallacy 'appeal to anger'. Here is an example for appeal to anger: Are you tired of being ignored by your government?  Is it right that the top 1% have so much when the rest of us have so little?  I urge you to vote for me today!\n",
        "Identify if this text contains the fallacy 'false dilemma'. Here is an example for false dilemma: Either you support this new legislation to give the police more power, or you want society to descend into chaos!\n",
        "Identify if this text contains the fallacy 'straw man'. Here is an example for straw man: Person 1: I think we should increase benefits for unemployed single mothers during the first year after childbirth because they need sufficient money to provide medical care for their children. Person 2: So you believe we should give incentives to women to become single mothers and get a free ride from the tax money of hard-working citizens. This is just going to hurt our economy and our society in the long run.\n",
        "Identify if this text contains the fallacy 'appeal to tradition'. Here is an example for appeal to tradition: This medicine has been used by people since ancient history, therefore it must be an effective way to treat diseases.\n",
        "Identify if this text contains the fallacy 'appeal to pity'. Here is an example for appeal to tradition: You must have graded my exam incorrectly. I studied very hard for weeks specifically because I knew my career depended on getting a good grade. If you give me a failing grade I'm ruined!\n",
        "Identify if this text contains the fallacy 'tu quoque'. Here is an example for tu quoque: You used to do that when you were my age.\"\"\"},\n",
        "    {\"role\": \"user\", \"content\": \"\"\"Let's think step by step:\n",
        "    1. Check if there is a logical fallacy in the text.\n",
        "    2. If there is a logical fallacy in the text, classify one of the following fallacies.\n",
        "    Please return your answer only in this exact format and nothing else: if there is no fallacy: {} or if there is a fallacy in the text: {fallacy_class}.\"\"\"}\n",
        "]\n",
        "\n",
        "prompt = pipeline.tokenizer.apply_chat_template(\n",
        "        prompt_messages,\n",
        "        tokenize=False,\n",
        "        add_generation_prompt=True\n",
        ")\n",
        "\n",
        "terminators = [\n",
        "    pipeline.tokenizer.eos_token_id,\n",
        "    pipeline.tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
        "]\n",
        "\n",
        "outputs = pipeline(\n",
        "    prompt,\n",
        "    max_new_tokens=512,\n",
        "    eos_token_id=terminators,\n",
        "    do_sample=True,\n",
        "    temperature=0.6,\n",
        "    top_p=0.9,\n",
        ")\n",
        "\n",
        "print(outputs[0][\"generated_text\"][len(prompt):])"
      ],
      "metadata": {
        "id": "NXwMi3FTQXuv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1bb5ee30-1b68-4b7d-c5db-1c6ba07373b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{ad populum}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the text to check for fallacies\n",
        "text_to_check = '''\n",
        "TITLE: What would people think about preventing people from switching out from a pilot seat? i.e. to a gunner position; you'd still be able to bail. POST: This is a ridiculous post and this mechanic will never be changed. Seat switching has always been a BF mechanic. Dont sit here and try and talk about realism or how you shouldnt be able to swap instantly between seats when there is hardly anything realistic about BF vehicle play in general. Sounds like you need to get better if you are having trouble shooting down the most vulnerable aircraft in the sky.\n",
        "'''\n",
        "\n",
        "\n",
        "# Construct the user message for prompting\n",
        "user_message = [\n",
        "    {\"role\": \"user\", \"content\": f\"\"\"You are a helpful assistant which is an expert in detecting logical fallacies!\n",
        "    Please go through the text and identify whether there is a logical fallacy in the following text, and if so, classify the text as the most appropriate logical fallacy:\n",
        "    {text_to_check}\\n\"\"\" +\n",
        "\"\"\"Identify if this text contains the fallacy 'slippery slope'. Here is an example for a slippery slope: Person A: “I think we should lower the legal drinking age.” Person B: “No, if we do that, we’ll have ten-year-olds getting drunk in bars!”\n",
        "Identify if this text contains the fallacy 'hasty generalization'. Here is an example for a hasty generalization: You have a transit flight via Frankfurt Airport, Germany. On the way to your gate, several passengers hastily bump into you without even apologizing. You conclude that “Germans are so rude!”\n",
        "Identify if this text contains the fallacy 'false analogy'. Here is an example for a false analogy: Love is like a spring shower. It brings refreshment to a person's body. (Does it also sometimes lead to thunderstorms and being hit by lightning?)\n",
        "Identify if this text contains the fallacy 'guilt by association'. Here is an example for guilt by association: This form of the argument is as follows: Group A makes a particular claim. Group B, which is currently viewed negatively by some, makes the same claim as Group A. Therefore, Group A is viewed as associated with Group B, and is now also viewed negatively. An example of this fallacy would be \"My opponent for office just received an endorsement from the Puppy Haters Association. Is that the sort of person you would want to vote for?\"\n",
        "Identify if this text contains the fallacy 'causal oversimplification'. Here is an example for causal oversimplification: 'I water the garden every day, which is why it grows so well.' Watering the garden is certainly one cause of its growth, but the soil quality, amount of sunlight, and number of pests in the area are also major causes.\n",
        "Identify if this text contains the fallacy 'ad populum'. Here is an example for ad populum: You’re at a bookstore browsing for books with a friend. Although you are an avid sci-fi reader, your friend picks up a memoir and tells you that you should read the book because it’s a bestseller.\n",
        "Identify if this text contains the fallacy 'circular reasoning'. Here is an example for circular reasoning: Parent: “It’s time to go to bed.” Child: “Why?” Parent: “Because this is your bedtime.”\n",
        "Identify if this text contains the fallacy 'appeal to fear'. Here is an example for appeal to fear: Either P or Q is true. Q is frightening. Therefore, P is true.\n",
        "Identify if this text contains the fallacy 'false causality'. Here is an example for false causality: Every time I bring my umbrella with me, it rains. Clearly, if I leave it at home, there will be sunshine!\n",
        "Identify if this text contains the fallacy 'fallacy of division'. Here is an example for fallacy of division: The second grade in Jefferson Elementary eats a lot of ice cream Carlos is a second-grader in Jefferson Elementary Therefore, Carlos eats a lot of ice cream\n",
        "Identify if this text contains the fallacy 'appeal to ridicule'. Here is an example for appeal to ridicule: Person A: At one time in prehistory, the continents were fused together into a single supercontinent, which we call Pangaea. Person B: Yes, I definitely believe that hundreds of millions of years ago, some laser cut through the Earth and broke apart a giant landmass into many different pieces.\n",
        "Identify if this text contains the fallacy 'appeal to worse problems'. Here is an example for appeal to worse problems: Everyone should wear seatbelts. We should also wear bibs and sleep in a bassinet.\n",
        "Identify if this text contains the fallacy 'abusive ad hominem'. Here is an example for abusive ad hominem: who is going to vote for a person looking like this?\n",
        "Identify if this text contains the fallacy 'appeal to false authority'. Here is an example for appeal to false authority: My favorite actor, who starred in that movie about a virus that turns people into zombies, said in an interview that genetically modified crops caused COVID-19. So I think that’s what really happened\n",
        "Identify if this text contains the fallacy 'appeal to positive emotion'. Here is an example for appeal to positive emotion: Your sibling is trying to convince you to let them eat the last piece of the dessert: “Can I have the last piece of cake? You know how much I love it, and it's been a tough day for me. I've had such a bad day, and this cake would just make me feel so much better.”\n",
        "Identify if this text contains the fallacy 'appeal to nature'. Here is an example for appeal to nature: Herbal medicine is natural, so it's good for you.\n",
        "Identify if this text contains the fallacy 'equivocation'. Here is an example for equivocation: Premise 1: Annoying co-workers are a headache. Premise 2: Painkillers can help you get rid of a headache. Conclusion: Painkillers can help you get rid of annoying co-workers.\n",
        "Identify if this text contains the fallacy 'appeal to anger'. Here is an example for appeal to anger: Are you tired of being ignored by your government?  Is it right that the top 1% have so much when the rest of us have so little?  I urge you to vote for me today!\n",
        "Identify if this text contains the fallacy 'false dilemma'. Here is an example for false dilemma: Either you support this new legislation to give the police more power, or you want society to descend into chaos!\n",
        "Identify if this text contains the fallacy 'straw man'. Here is an example for straw man: Person 1: I think we should increase benefits for unemployed single mothers during the first year after childbirth because they need sufficient money to provide medical care for their children. Person 2: So you believe we should give incentives to women to become single mothers and get a free ride from the tax money of hard-working citizens. This is just going to hurt our economy and our society in the long run.\n",
        "Identify if this text contains the fallacy 'appeal to tradition'. Here is an example for appeal to tradition: This medicine has been used by people since ancient history, therefore it must be an effective way to treat diseases.\n",
        "Identify if this text contains the fallacy 'appeal to pity'. Here is an example for appeal to tradition: You must have graded my exam incorrectly. I studied very hard for weeks specifically because I knew my career depended on getting a good grade. If you give me a failing grade I'm ruined!\n",
        "Identify if this text contains the fallacy 'tu quoque'. Here is an example for tu quoque: You used to do that when you were my age.\n",
        "Let's think step by step:\n",
        "1. Check if there is a logical fallacy in the text.\n",
        "2. If there is a logical fallacy in the text, classify one of the following fallacies.\n",
        "Please return your answer only in this exact format and nothing else: if there is no fallacy: {} or if there is a fallacy in the text: {fallacy_class}.\"\"\"}\n",
        "]\n",
        "\n",
        "prompt = pipeline.tokenizer.apply_chat_template(\n",
        "        user_message,\n",
        "        tokenize=False,\n",
        "        add_generation_prompt=True\n",
        ")\n",
        "\n",
        "terminators = [\n",
        "    pipeline.tokenizer.eos_token_id,\n",
        "    pipeline.tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
        "]\n",
        "\n",
        "outputs = pipeline(\n",
        "    prompt,\n",
        "    max_new_tokens=512,\n",
        "    eos_token_id=terminators,\n",
        "    do_sample=True,\n",
        "    temperature=0.6,\n",
        "    top_p=0.9,\n",
        ")\n",
        "\n",
        "print(outputs[0][\"generated_text\"][len(prompt):])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kQvTCBc8tZI9",
        "outputId": "d2cf3ad6-276c-4c30-d130-af6c41ceab7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{appeal to ridicule}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sQwH_Uo4uDW_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}